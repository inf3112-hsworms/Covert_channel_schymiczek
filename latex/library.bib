Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Williams2006,
abstract = {The identification of network applications through observation of associated packet traffic flows is vital to the areas of network management and surveillance. Currently popular methods such as port number and payload-based identification exhibit a number of shortfalls. An alternative is to use machine learning (ML) techniques and identify network applications based on per-flow statistics, derived from payload-independent features such as packet length and inter-arrival time distributions. The performance impact of feature set reduction, using Consistency-based and Correlation-based feature selection, is demonstrated on Na{\"{i}}ve Bayes, C4.5, Bayesian Network and Na{\"{i}}ve Bayes Tree algorithms. We then show that it is useful to differentiate algorithms based on computational performance rather than classification accuracy alone, as although classification accuracy between the algorithms is similar, computational performance can differ significantly.},
author = {Williams, Nigel and Zander, Sebastian and Armitage, Grenville},
doi = {10.1145/1163593.1163596},
file = {:home/jeff/Downloads/1163593.1163596.pdf:pdf},
issn = {0146-4833},
journal = {ACM SIGCOMM Comput. Commun. Rev.},
keywords = {Machine learning,Traffic classification},
month = {oct},
number = {5},
pages = {5--16},
title = {{A preliminary performance comparison of five machine learning algorithms for practical IP traffic flow classification}},
url = {https://dl.acm.org/doi/10.1145/1163593.1163596},
volume = {36},
year = {2006}
}
@article{Elguea2017,
abstract = {Comparing two or more routes on Internet is difficult owing to the variability of the measurements resulting from the different routes or use conditions. With current tools such as SDN[1], it is important to determine with certainty which the best route between a user and an internet service. This will be achieved with fast measurements which do not affect the operation of the network. With trends such as IoT, the best routes can be identified based on latency and not just on the jumps between autonomous systems, fact that optimizes data traffic in a specific way whether it is IPv4 or IPv6. As time elapses, it becomes more important to have a perfect setting for the LAN, which means optimal DNS, LDAP Servers appropriate number, etc. Thats why we propose a precise method that contemplates every possible variation of data, thus making a comparison by means of the use of confidence limits.},
author = {Elguea, Lorenzo M. and Martinez-Rios, Felix},
doi = {10.1016/j.procs.2017.10.076},
file = {:home/jeff/Downloads/1-s2.0-S1877050917321269-main.pdf:pdf},
isbn = {9781510849914},
issn = {18770509},
journal = {Procedia Comput. Sci.},
keywords = {BGP,Compare,Latency,SDN,Statistics,Variance},
pages = {393--400},
publisher = {Elsevier B.V.},
title = {{An efficient method to compare latencies in order to obtain the best route for SDN}},
url = {https://doi.org/10.1016/j.procs.2017.10.076},
volume = {116},
year = {2017}
}
@article{Dempster2020,
abstract = {Most methods for time series classification that attain state-of-the-art accuracy have high computational complexity, requiring significant training time even for smaller datasets, and are intractable for larger datasets. Additionally, many existing methods focus on a single type of feature such as shape or frequency. Building on the recent success of convolutional neural networks for time series classification, we show that simple linear classifiers using random convolutional kernels achieve state-of-the-art accuracy with a fraction of the computational expense of existing methods. Using this method, it is possible to train and test a classifier on all 85 ‘bake off' datasets in the UCR archive in '2h, and it is possible to train a classifier on a large dataset of more than one million time series in approximately 1 h.},
annote = {very interesting},
author = {Dempster, Angus and Petitjean, Fran{\c{c}}ois and Webb, Geoffrey I.},
doi = {10.1007/s10618-020-00701-z},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dempster, Petitjean, Webb - 2020 - ROCKET exceptionally fast and accurate time series classification using random convolutional kernels.pdf:pdf},
issn = {1384-5810},
journal = {Data Min. Knowl. Discov.},
keywords = {Convolution,Random,Scalable,Time series classification},
month = {sep},
number = {5},
pages = {1454--1495},
publisher = {Springer},
title = {{ROCKET: exceptionally fast and accurate time series classification using random convolutional kernels}},
url = {https://link.springer.com/10.1007/s10618-020-00701-z},
volume = {34},
year = {2020}
}
@article{Jordanova2017,
abstract = {Different questions related with analysis of extreme values and outliers arise frequently in practice. To exclude extremal observations and outliers is not a good decision because they contain important information about the observed distribution. The difficulties with their usage are usually related to the estimation of the tail index in case it exists. There are many measures for the center of the distribution, e.g. mean, mode, median. There are many measures of the variance, asymmetry, and kurtosis, but there is no easy characteristic for heavy-tailedness of the observed distribution. Here we propose such a measure, give some examples and explore some of its properties. This allows us to introduce a classification of the distributions, with respect to their heavy-tailedness. The idea is to help and navigate practitioners for accurate and easier work in the field of probability distributions. Using the properties of the defined characteristics some distribution sensitive extremal index estimators are proposed and their properties are partially investigated.},
archivePrefix = {arXiv},
arxivId = {1707.01308v1},
author = {Jordanova, Pavlina K. and Petkova, Monika P.},
doi = {10.1063/1.5013996},
eprint = {1707.01308v1},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jordanova, Petkova - 2017 - Measuring heavy-tailedness of distributions.pdf:pdf},
journal = {AIP Conf. Proc.},
month = {jul},
publisher = {American Institute of Physics Inc.},
title = {{Measuring heavy-tailedness of distributions}},
url = {http://arxiv.org/abs/1707.01308 http://dx.doi.org/10.1063/1.5013996},
volume = {1910},
year = {2017}
}
@article{Kirichenko2019,
abstract = {The article presents a novel method of fractal time series classification by meta-algorithms based on decision trees. The classification objects are fractal time series. For modeling, binomial stochastic cascade processes are chosen. Each class that was singled out unites model time series with the same fractal properties. Numerical experiments demonstrate that the best results are obtained by the random forest method with regression trees. A comparative analysis of the classification approaches, based on the random forest method, and traditional estimation of self-similarity degree are performed. The results show the advantage of machine learning methods over traditional time series evaluation. The results were used for detecting denial-of-service (DDoS) attacks and demonstrated a high probability of detection.},
author = {Kirichenko, Lyudmyla and Radivilova, Tamara and Bulakh, Vitalii},
doi = {10.3390/data4010005},
file = {:home/jeff/Desktop/SynologyDrive/projekte/Bachelor/papers/data-04-00005.pdf:pdf},
issn = {23065729},
journal = {Data},
keywords = {Binomial stochastic cascade,Classification of time series,Detecting distributed denial-of-service attacks,Fractal time series,Hurst exponent,Random forest},
number = {1},
pages = {1--13},
title = {{Machine learning in classification time series with fractal properties}},
volume = {4},
year = {2019}
}
@article{Informatik2021,
author = {Informatik, Von Der Fakult{\"{a}}t},
file = {:home/jeff/Downloads/dissertation{\_}hou{\_}20210610.pdf:pdf},
title = {{Performability Analysis of Network-on-Chips}},
year = {2021}
}
@article{Goovaerts2005,
author = {Goovaerts, Marc J and Kaas, R O B and Laeven, Roger J A and Tang, Qihe},
doi = {10.1080/03461230500361943},
file = {:home/jeff/Downloads/The tail probability of discounted sums of Pareto-like losses in insurance.pdf:pdf},
keywords = {62e20,62p05,91b30,asymptotics,elliptical distribution,log,mathematics subject ciassificatloir,normal variance-mean mixed distribution,pareto-like distribution,tail probability},
pages = {446--461},
title = {{The tail probability of discounted sums of Pareto-like losses in insurance}},
year = {2005}
}
@article{numpy,
abstract = {Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves 1 and in the first imaging of a black hole 2 . Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
archivePrefix = {arXiv},
arxivId = {2006.10256},
author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, St{\'{e}}fan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del R{\'{i}}o, Jaime Fern{\'{a}}ndez and Wiebe, Mark and Peterson, Pearu and G{\'{e}}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
doi = {10.1038/s41586-020-2649-2},
eprint = {2006.10256},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harris et al. - 2020 - Array programming with NumPy.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {sep},
number = {7825},
pages = {357--362},
pmid = {32939066},
publisher = {Nature Research},
title = {{Array programming with NumPy}},
url = {https://www.nature.com/articles/s41586-020-2649-2},
volume = {585},
year = {2020}
}
@article{Ahmed2010,
abstract = {In this work we present a large scale comparison study for the major machine learning models for time series forecasting. Specifically, we apply the models on the monthly M3 time series competition data (around a thousand time series). There have been very few, if any, large scale comparison studies for machine learning models for the regression or the time series forecasting problems, so we hope this study would fill this gap. The models considered are multilayer perceptron, Bayesian neural networks, radial basis functions, generalized regression neural networks (also called kernel regression), K-nearest neighbor regression, {\{}CART{\}} regression trees, support vector regression, and Gaussian processes. The study reveals significant differences between the different methods. The best two methods turned out to be the multilayer perceptron and the Gaussian process regression. In addition to model comparisons, we have tested different preprocessing methods and have shown that they have different impacts on the performance.},
author = {Ahmed, Nesreen K and Atiya, Amir F and Gayar, Neamat El and El-shishiny, Hisham},
file = {:home/jeff/Desktop/SynologyDrive/projekte/Bachelor/papers/10.1.1.114.8923.pdf:pdf},
journal = {Thiese},
keywords = {comparison study,gaussian process regression,machine learning models,network forecasting,neural,support vector regression},
pages = {594--621},
title = {{an Empirical Comparison of Machine Learning}},
volume = {29},
year = {2010}
}
@article{Nadarajah2006,
author = {Nadarajah, S and Espejo, M R},
file = {:home/jeff/Downloads/1143122388.pdf:pdf},
pages = {72--83},
title = {{SUMS, PRODUCTS, AND RATIOS FOR THE GENERALIZED BIVARIATE PARETO DISTRIBUTION Saralees Nadarajah and Mariano Ruiz Espejo}},
volume = {29},
year = {2006}
}
@article{Hohn2004,
author = {Hohn, N and Veitch, D and Papagiannaki, K and Diot, C},
file = {:home/jeff/Downloads/HV+05-routerdelay.pdf:pdf},
keywords = {darryl veitch and kon-,packet delay analysis,router model,stantina papagiannaki were with,the sprint advanced technology,this work was done,when nicolas hohn},
pages = {355--366},
title = {{Bridging Router Performance and Queuing Theory Categories and Subject Descriptors}},
year = {2004}
}
@article{Voitalov2019,
abstract = {We bring rigor to the vibrant activity of detecting power laws in empirical degree distributions in real-world networks. We first provide a rigorous definition of power-law distributions, equivalent to the definition of regularly varying distributions that are widely used in statistics and other fields. This definition allows the distribution to deviate from a pure power law arbitrarily but without affecting the power-law tail exponent. We then identify three estimators of these exponents that are proven to be statistically consistent -- that is, converging to the true value of the exponent for any regularly varying distribution -- and that satisfy some additional niceness requirements. In contrast to estimators that are currently popular in network science, the estimators considered here are based on fundamental results in extreme value theory, and so are the proofs of their consistency. Finally, we apply these estimators to a representative collection of synthetic and real-world data. According to their estimates, real-world scale-free networks are definitely not as rare as one would conclude based on the popular but unrealistic assumption that real-world data comes from power laws of pristine purity, void of noise and deviations.},
archivePrefix = {arXiv},
arxivId = {1811.02071},
author = {Voitalov, Ivan and van der Hoorn, Pim and van der Hofstad, Remco and Krioukov, Dmitri},
doi = {10.1103/PhysRevResearch.1.033034},
eprint = {1811.02071},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Voitalov et al. - 2019 - Scale-free networks well done(2).pdf:pdf},
issn = {2643-1564},
journal = {Phys. Rev. Res.},
keywords = {doi:10.1103/PhysRevResearch.1.033034 url:https://d},
month = {oct},
number = {3},
pages = {033034},
publisher = {American Physical Society},
title = {{Scale-free networks well done}},
url = {https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.1.033034 http://arxiv.org/abs/1811.02071 http://dx.doi.org/10.1103/PhysRevResearch.1.033034 https://link.aps.org/doi/10.1103/PhysRevResearch.1.033034},
volume = {1},
year = {2019}
}
@inproceedings{Mazurczyk2019,
address = {New York, NY, USA},
author = {Mazurczyk, Wojciech and Szary, Przemys{\l}aw and Wendzel, Steffen and Caviglione, Luca},
booktitle = {Proc. 14th Int. Conf. Availability, Reliab. Secur.},
doi = {10.1145/3339252.3341493},
file = {:home/jeff/Downloads/camera{\_}ready{\_}paper{\_}268.pdf:pdf},
isbn = {9781450371643},
keywords = {covert channels,information hid-,ing,network steganography,reversible data hiding},
month = {aug},
pages = {1--8},
publisher = {ACM},
title = {{Towards Reversible Storage Network Covert Channels}},
url = {https://dl.acm.org/doi/10.1145/3339252.3341493},
year = {2019}
}
@article{Vural2018,
abstract = {Supervised manifold learning methods learn data representations by preserving the geometric structure of data while enhancing the separation between data samples from different classes. In this work, we propose a theoretical study of supervised manifold learning for classification. We consider nonlinear dimensionality reduction algorithms that yield linearly separable embeddings of training data and present generalization bounds for this type of algorithms. A necessary condition for satisfactory generalization performance is that the embedding allow the construction of a sufficiently regular interpolation function in relation with the separation margin of the embedding. We show that for supervised embeddings satisfying this condition, the classification error decays at an exponential rate with the number of training samples. Finally, we examine the separability of supervised nonlinear embeddings that aim to preserve the low-dimensional geometric structure of data based on graph representations. The proposed analysis is supported by experiments on several real data sets.},
archivePrefix = {arXiv},
arxivId = {1507.05880},
author = {Vural, Elif and Guillemot, Christine},
eprint = {1507.05880},
file = {:home/jeff/Downloads/15-373.pdf:pdf},
issn = {15337928},
journal = {J. Mach. Learn. Res.},
keywords = {Classification,Dimensionality reduction,Manifold learning,Out-of-sample extensions,RBF interpolation},
pages = {1--55},
title = {{A study of the classification of low-dimensional data with supervised manifold learning}},
volume = {18},
year = {2018}
}
@article{Cai2018,
author = {Cai, Yaping and Guan, Kaiyu and Peng, Jian and Wang, Shaowen and Seifert, Christopher},
file = {:home/jeff/Downloads/1-s2.0-S0034425718300610-am{\_}s0.pdf:pdf},
pages = {1--50},
title = {{A high-performance and in-season classification system of field-level crop types using time-series Landsat data and a machine learning approach}},
year = {2018}
}
@article{Balaji2015,
abstract = {Automatic classification cardiac views is the first step to automate wall motion analysis, computer aided disease diagnosis, measurement computation etc. In this paper a fully automatic classification of cardiac view in echocardiogram is proposed. The system is built based on a machine learning approach which characterizes two features 1) Histogram features and 2) Statistical features. In this system four standard views parasternal short axis (PSAX), parasternal long axis (PLAX), apical two chamber (A2C) and apical four chamber (A4C) views are classified. Experiments over 200 echocardiogram images show that the proposed method with an accuracy of 87.5{\%} can be effectively used in cardiac view classification.},
author = {Balaji, G. N. and Subashini, T. S. and Chidambaram, N.},
doi = {10.1016/j.procs.2015.02.084},
file = {:home/jeff/Downloads/1-s2.0-S1877050915001489-main(1).pdf:pdf},
issn = {18770509},
journal = {Procedia Comput. Sci.},
keywords = {Apical two chamber (A2C) and apical four chamber (,Parasternal long axis (PLAX),Parasternal short axis (PSAX)},
number = {Icict 2014},
pages = {1569--1576},
publisher = {Elsevier Masson SAS},
title = {{Automatic classification of cardiac views in echocardiogram using histogram and statistical features}},
url = {http://dx.doi.org/10.1016/j.procs.2015.02.084},
volume = {46},
year = {2015}
}
@article{Ismail2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1809.04356v4},
author = {Ismail, Hassan and Germain, Fawaz and Weber, Jonathan},
eprint = {arXiv:1809.04356v4},
file = {:home/jeff/Downloads/1809.04356.pdf:pdf},
keywords = {Interesting,classification,deep learning,review,time series},
mendeley-tags = {Interesting},
pages = {1--44},
title = {{Deep learning for time series classification : a review}},
year = {2018}
}
@article{Karim2019,
abstract = {Over the past decade, multivariate time series classification has received great attention. We propose transforming the existing univariate time series classification models, the Long Short Term Memory Fully Convolutional Network (LSTM-FCN) and Attention LSTM-FCN (ALSTM-FCN), into a multivariate time series classification model by augmenting the fully convolutional block with a squeeze-and-excitation block to further improve accuracy. Our proposed models outperform most state-of-the-art models while requiring minimum preprocessing. The proposed models work efficiently on various complex multivariate time series classification tasks such as activity recognition or action recognition. Furthermore, the proposed models are highly efficient at test time and small enough to deploy on memory constrained systems.},
archivePrefix = {arXiv},
arxivId = {1801.04503},
author = {Karim, Fazle and Majumdar, Somshubra and Darabi, Houshang and Harford, Samuel},
doi = {10.1016/J.NEUNET.2019.04.014},
eprint = {1801.04503},
issn = {18792782},
journal = {Neural Networks},
keywords = {Convolutional neural network,Long short term memory,Multivariate time series classification,Recurrent neural network},
month = {aug},
pages = {237--245},
pmid = {31121421},
publisher = {Elsevier Ltd},
title = {{Multivariate LSTM-FCNs for time series classification}},
volume = {116},
year = {2019}
}
@article{Nguyen2015,
abstract = {Nowadays, with the advance of technology, many applications generate huge amounts of data streams at very high speed. Examples include network traffic, web click streams, video surveillance, and sensor networks. Data stream mining has become a hot research topic. Its goal is to extract hidden knowledge/patterns from continuous data streams. Unlike traditional data mining where the dataset is static and can be repeatedly read many times, data stream mining algorithms face many challenges and have to satisfy constraints such as bounded memory, single-pass, real-time response, and concept-drift detection. This paper presents a comprehensive survey of the state-of-the-art data stream mining algorithms with a focus on clustering and classification because of their ubiquitous usage. It identifies mining constraints, proposes a general model for data stream mining, and depicts the relationship between traditional data mining and data stream mining. Furthermore, it analyzes the advantages as well as limitations of data stream algorithms and suggests potential areas for future research.},
author = {Nguyen, Hai-Long and Woon, Yew-Kwong and Ng, Wee-Keong},
doi = {10.1007/s10115-014-0808-1},
file = {:home/jeff/Downloads/DSM-review.pdf:pdf},
issn = {0219-1377},
journal = {Knowl. Inf. Syst.},
keywords = {Classification,Clustering,Data stream mining,Survey},
month = {dec},
number = {3},
pages = {535--569},
title = {{A survey on data stream clustering and classification}},
url = {http://link.springer.com/10.1007/s10115-014-0808-1},
volume = {45},
year = {2015}
}
@phdthesis{Plaud2019,
author = {Plaud, Ang{\'{e}}line and Nguifo, Engelbert and Charreyron, Jacques and Plaud, Ang{\'{e}}line and Nguifo, Engelbert and Charreyron, Jacques},
file = {:home/jeff/Downloads/plaud{\_}etal{\_}ecml{\_}2019.pdf:pdf},
title = {{Multivariate time series classification based on M-histograms and multi-view}},
year = {2019}
}
@inproceedings{Pfitzinger2018a,
abstract = {Taking a newly collected large data set on the TCP connection termination latency in GPRS networks we try to identify the underlying statistical distribution. The data extends the observed latencies to large time scales necessitating a heavy-tail distribution. Many distributions work well for the main body of the data. However, the heavy tail of the distribution benefits from mixing different statistical distributions. We compare several distributions and find that the double Pareto-lognormal distribution and the generalized Beta distribution of the second kind fit the data equally well.},
annote = {20},
author = {Pfitzinger, Bernd and Baumann, Tommy and Emde, Andreas and Macos, Dragan and Jest{\"{a}}dt, Thomas},
booktitle = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
doi = {10.24251/HICSS.2018.730},
file = {:home/jeff/Downloads/paper0732.pdf:pdf},
isbn = {9780998133119},
issn = {15301605},
pages = {5825--5830},
title = {{Modeling the GPRS Network Latency with a Double Pareto-lognormal or a Generalized Beta Distribution}},
url = {http://hdl.handle.net/10125/50619},
volume = {2018-Janua},
year = {2018}
}
@article{Bertsekas1992,
abstract = {2nd ed. Introduction and layered network architecture -- Point-to-point protocols and links -- Delay models in data networks -- Multiaccess communication -- Routing in data networks -- Flow control.},
author = {Bertsekas, Dimitri P. (MIT) and Gallager, Robert (MIT)},
file = {:home/jeff/Downloads/Queueing{\_}Data{\_}Nets.pdf:pdf},
isbn = {9780132009164},
journal = {Data Networks},
pages = {149--269},
title = {{Delay Models in Data Networks}},
year = {1992}
}
@article{Maarouf2021,
abstract = {Machine learning and deep learning algorithms can be used to classify encrypted Internet traffic. Classification of encrypted traffic can become more challenging in the presence of adversarial attacks that target the learning algorithms. In this paper, we focus on investigating the effectiveness of different evasion attacks and see how resilient machine and deep learning algorithms are. Namely, we test C4.5 Decision Tree, K-Nearest Neighbor (KNN), Artificial Neural Network (ANN), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). In most of our experimental results, deep learning shows better resilience against the adversarial samples in comparison to machine learning. Whereas, the impact of the attack varies depending on the type of attack.},
archivePrefix = {arXiv},
arxivId = {2105.14564},
author = {Maarouf, Ramy and Sattar, Danish and Matrawy, Ashraf},
doi = {10.1109/ISCC53001.2021.9631407},
eprint = {2105.14564},
file = {:home/jeff/Downloads/2105.14564v1.pdf:pdf},
isbn = {9781665427449},
issn = {15301346},
journal = {Proc. - IEEE Symp. Comput. Commun.},
keywords = {Encrypted traffic classification,adversarial samples,deep learning,machine learning},
title = {{Evaluating Resilience of Encrypted Traffic Classification against Adversarial Evasion Attacks}},
volume = {2021-Septe},
year = {2021}
}
@article{Su2018,
abstract = {Low-dimensional discriminative representations enhance machine learning methods in both performance and complexity, motivating supervised dimensionality reduction (DR) that transforms high-dimensional data to a discriminative sub-space. Most DR methods require data to be i.i.d., however, in some domains, data naturally come in sequences, where the observations are temporally correlated. We propose a DR method called LT-LDA to learn low-dimensional temporal representations. We construct the separability among sequence classes by lifting the holistic temporal structures, which are established based on temporal alignments and may change in different subspaces. We jointly learn the subspace and the associated alignments by optimizing an objective which favors easily-separable temporal structures, and show that this objective is connected to the inference of alignments, thus allows an iterative solution. We provide both theoretical insight and empirical evaluation on real-world sequence datasets to show the interest of our method.},
author = {Su, Bing and Wu, Ying},
file = {:home/jeff/Downloads/su18a.pdf:pdf;:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su, Wu - 2018 - Learning low-dimensional temporal representations.pdf:pdf},
isbn = {9781510867963},
journal = {35th Int. Conf. Mach. Learn. ICML 2018},
pages = {7578--7587},
title = {{Learning low-dimensional temporal representations}},
volume = {11},
year = {2018}
}
@article{Kirichenko2021,
author = {Kirichenko, Lyudmyla and Radivilova, Tamara and Stepanenko, Juliia},
file = {:home/jeff/Downloads/paper128.pdf:pdf},
isbn = {0000000159},
keywords = {e с g time,machine learning classification,numerical recurrence characteristic,recurrence plot,series,time series classification},
pages = {0--2},
title = {{Applying recurrence plots to classify time series}},
volume = {0269},
year = {2021}
}
@article{Zhao2021,
abstract = {Traffic classification groups similar or related traffic data, which is one main stream technique of data fusion in the field of network management and security. With the rapid growth of network users and the emergence of new networking services, network traffic classification has attracted increasing attention. Many new traffic classification techniques have been developed and widely applied. However, the existing literature lacks a thorough survey to summarize, compare and analyze the recent advances of network traffic classification in order to deliver a holistic perspective. This paper carefully reviews existing network traffic classification methods from a new and comprehensive perspective by classifying them into five categories based on representative classification features, i.e., statistics-based classification, correlation-based classification, behavior-based classification, payload-based classification, and port-based classification. A series of criteria are proposed for the purpose of evaluating the performance of existing traffic classification methods. For each specified category, we analyze and discuss the details, advantages and disadvantages of its existing methods, and also present the traffic features commonly used. Summaries of investigation are offered for providing a holistic and specialized view on the state-of-art. For convenience, we also cover a discussion on the mostly used datasets and the traffic features adopted for traffic classification in the review. At the end, we identify a list of open issues and future directions in this research field.},
author = {Zhao, Jingjing and Jing, Xuyang and Yan, Zheng and Pedrycz, Witold},
doi = {10.1016/j.inffus.2021.02.009},
file = {:home/jeff/Downloads/Zhao{\_}Network{\_}traffic{\_}classification{\_}for{\_}data{\_}fusion.pdf:pdf},
issn = {15662535},
journal = {Inf. Fusion},
keywords = {Data fusion,Machine learning,Security management,Traffic classification},
month = {aug},
pages = {22--47},
publisher = {Elsevier B.V.},
title = {{Network traffic classification for data fusion: A survey}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S156625352100018X},
volume = {72},
year = {2021}
}
@article{Begtaseviu2000,
author = {Begta{\v{s}}evi{\"{u}}, F and Mieghem, P Van},
file = {:home/jeff/Downloads/hopcountmeasurementPAM.pdf:pdf},
journal = {Measurement},
pages = {1--12},
title = {{Measurements of the Hopcount in Internet}},
year = {2000}
}
@article{Hooghiemstra,
author = {Hooghiemstra, Gerard and Mieghem, Piet Van},
file = {:home/jeff/Downloads/e2eDelayRipe{\_}IEEE.pdf:pdf},
keywords = {end-to-end delay,stochastic modeling},
title = {{Delay Distributions on Fixed Internet Paths}},
year = {2001}
}
@article{Hosamo2017,
author = {Hosamo, Mohsen},
doi = {10.12691/jcn-4-1-2},
file = {:home/jeff/Downloads/10.1.1.1059.9802.pdf:pdf},
keywords = {1,10,11-19,12691,2017,4,cite this article,density function,doi,jcn-4-1-2,journal,memory access time,mohsen hosamo,no,of computer networks,output rate,pareto distribution,pareto traffic generator,probability,queue length,round-robin fashion,shape parameter,source traffic modeling using,switch input,uniformly distributed random number,vol},
number = {1},
pages = {11--19},
title = {{Source Traffic Modeling Using Pareto Traffic Generator}},
volume = {4},
year = {2017}
}
@article{Willinger1997,
author = {Willinger, Walter and Taqqu, M.S. and Sherman, Robert and Wilson, D.V.},
doi = {10.1109/90.554723},
file = {:home/jeff/Downloads/willinger.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Trans. Netw.},
number = {1},
pages = {71--86},
title = {{Self-similarity through high-variability: statistical analysis of Ethernet LAN traffic at the source level}},
url = {http://ieeexplore.ieee.org/document/554723/},
volume = {5},
year = {1997}
}
@book{Gligor1994,
author = {Gligor, V.D.},
booktitle = {NCSC-TG-030, Libr. No. S-240,572, Version 1},
file = {:home/jeff/Downloads/Covert{\_}Channel{\_}Analysis{\_}of{\_}Trusted{\_}Systems{\_}A{\_}Guide.pdf:pdf},
number = {November},
title = {{A guide to understanding covert channel analysis of trusted systems}},
year = {1993}
}
@article{Chakravarty2014,
author = {Chakravarty, Sambuddho},
file = {:home/jeff/Downloads/Chakravarty{\_}columbia{\_}0054D{\_}11826.pdf:pdf},
title = {{Traffic Analysis Attacks and Defenses in Low Latency Anonymous Communication}},
year = {2014}
}
@misc{zipf_web,
title = {{Zipf's Law Applied to Word and Letter Frequencies}},
url = {https://www.wolframcloud.com/objects/demonstrations/ZipfsLawAppliedToWordAndLetterFrequencies-source.nb},
urldate = {2022-05-10}
}
@article{Goonatilake2012,
abstract = {Network latency causes a delay in transmitting a message from one location to another. This can be attributed to several other factors, such as network congestion, network traffic, and computer storage capacities. Of course, the distance between two locations is the main factor that contributes to the delay. Since transmission between two cities will not be a straight path, latency is subject to detour and can be a factor of any deviation between these cities. These factors, along with a loss of the data and energy aspects of the transmission, will be investigated as this paper attempts to summarize latency estimation using regression and numerical models. Path prediction can be done up to a number of transmission towers or satellites between two cities. Latency estimation to locate either the client, client server, or host will be analyzed using a liner regression model leading to the same numerical model. Reliability analysis stemming from latency will be done at the end of this article.},
author = {Goonatilake, Rohitha and Bachnak, Rafic A.},
doi = {10.5539/nct.v1n2p1},
file = {:home/jeff/Downloads/5d221678e6b542391c831e87fca56e830a73.pdf:pdf},
issn = {1927-0658},
journal = {Netw. Commun. Technol.},
keywords = {and packets,communication,distance,latency,network,reliability,wireless},
month = {aug},
number = {2},
pages = {1--11},
title = {{Modeling Latency in a Network Distribution}},
url = {http://www.ccsenet.org/journal/index.php/nct/article/view/20122},
volume = {1},
year = {2012}
}
@inproceedings{Chourib2019,
abstract = {Network covert channels break a computer's security policy to establish a stealthy communication. They are a threat being increasingly used by malicious software. Most previous studies on detecting network covert channels using Machine Learning (ML) were tested with a dataset that was created using one single covert channel tool and also are ineffective at classifying covert channels into patterns. In this paper, selected ML methods are applied to detect popular network covert channels. The capacity of detecting and classifying covert channels with high precision is demonstrated. A dataset was created from nine standard covert channel tools and the covert channels are then accordingly classified into patterns and labelled. Half of the generated dataset is used to train three different ML algorithms. The remaining half is used to verify the algorithms' performance. The tested ML algorithms are Support Vector Machines (SVM), k-Nearest Neighbors (k-NN) and Deep Neural Networks (DNN). The k-NN model demonstrated the highest precision rate at 98{\%} detection of a given covert channel and with a low false positive rate of 1{\%}.},
author = {Chourib, Mehdi},
booktitle = {2019 Int. Conf. High Perform. Comput. Simul.},
doi = {10.1109/HPCS48598.2019.9188115},
file = {:home/jeff/Downloads/Papers/Detecting{\_}Selected{\_}Network{\_}Covert{\_}Channels{\_}Using{\_}Machine{\_}Learning.pdf:pdf},
isbn = {978-1-7281-4484-9},
keywords = {Active warden,Data leakage protection,Information hiding,Network steganography},
month = {jul},
pages = {582--588},
publisher = {IEEE},
title = {{Detecting Selected Network Covert Channels Using Machine Learning}},
url = {https://ieeexplore.ieee.org/document/9188115/},
year = {2019}
}
@article{Janardan2017,
abstract = {In this digital era we are surrounded by social media applications and the hardware devices (such as sensorsetc) which are pouring data at an astonishing rate. This incoming data from heterogeneous sources is referred as data stream. Analysing data in motion (data streams) has become new challenge in order to meet the demands of real time analytics. Conventional mining techniques are proving inefficient since the behaviour of data itself has changed. Other challenges associated with data streams include resources constraints like memory and running time along with single scan of the data. Due to the time variant nature of data streams, applying any mining algorithm such as classification, clustering, indexing in a single scan of data is a tedious task. This paper focuses on concept drift problem in classification of streaming data. During classification a change in the concept or distribution of dataset over the time is termed as concept drift. The performance of a model/classifier degrades due to concept drift even in stationary data; dealing with this problem hence become more challenging in data streams. This paper presents categorization of existing streaming data classification algorithms along with their ability to solve concept drift problem. It also presents comparison of various tools available for simulating such problems along with their limitations. The paper also lists the various datasets and performance metrics that have been used in literature for performance analysis. Thus, this paper may serve as a complete roadmap for the researchers interested in designing new solutions for solving concept drift problem in streaming data classification. It also highlights the open research questions in this field.},
author = {Janardan and Mehta, Shikha},
doi = {10.1016/j.procs.2017.11.440},
file = {:home/jeff/Downloads/1-s2.0-S1877050917326881-main(1).pdf:pdf},
issn = {18770509},
journal = {Procedia Comput. Sci.},
keywords = {Apache Spark,Apache Storm,Classification,MOA,Samoa,concept drift,data streams},
pages = {804--811},
publisher = {Elsevier B.V.},
title = {{Concept drift in Streaming Data Classification: Algorithms, Platforms and Issues}},
url = {https://doi.org/10.1016/j.procs.2017.11.440 https://linkinghub.elsevier.com/retrieve/pii/S1877050917326881},
volume = {122},
year = {2017}
}
@article{Al-Eidi2021,
abstract = {With the rapid growth of data exfiltration carried out by cyber attacks, Covert Timing Channels (CTC) have become an imminent network security risk that continues to grow in both sophistication and utilization. These types of channels utilize inter-arrival times to steal sensitive data from the targeted networks. CTC detection relies increasingly on machine learning techniques, which utilize statistical-based metrics to separate malicious (covert) traffic flows from the legitimate (overt) ones. However, given the efforts of cyber attacks to evade detection and the growing column of CTC, covert channels detection needs to improve in both performance and precision to detect and prevent CTCs and mitigate the reduction of the quality of service caused by the detection process. In this article, we present an innovative image-based solution for fully automated CTC detection and localization. Our approach is based on the observation that the covert channels generate traffic that can be converted to colored images. Leveraging this observation, our solution is designed to automatically detect and locate the malicious part (i.e., set of packets) within a traffic flow. By locating the covert parts within traffic flows, our approach reduces the drop of the quality of service caused by blocking the entire traffic flows in which covert channels are detected. We first convert traffic flows into colored images, and then we extract image-based features for detection covert traffic. We train a classifier using these features on a large data set of covert and overt traffic. This approach demonstrates a remarkable performance achieving a detection accuracy of 95.83{\%} for cautious CTCs and a covert traffic accuracy of 97.83{\%} for 8 bit covert messages, which is way beyond what the popular statistical-based solutions can achieve.},
annote = {page 1-2 good description of

Interesting: 23 47 22 24},
author = {Al-Eidi, Shorouq and Darwish, Omar and Chen, Yuanzhu and Husari, Ghaith},
doi = {10.1109/ACCESS.2020.3046234},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Eidi et al. - 2021 - SnapCatch Automatic Detection of Covert Timing Channels Using Image Processing and Machine Learning.pdf:pdf},
issn = {2169-3536},
journal = {IEEE Access},
keywords = {Covert timing channels,detection,entropy,image processing,machine learning},
pages = {177--191},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{SnapCatch: Automatic Detection of Covert Timing Channels Using Image Processing and Machine Learning}},
url = {https://ieeexplore.ieee.org/document/9301285/},
volume = {9},
year = {2021}
}
@article{Papagiannaki2003,
author = {Papagiannaki, Konstantina and Moon, Sue and Fraleigh, Chuck and Thiran, P. and Diot, C.},
doi = {10.1109/JSAC.2003.814410},
file = {:home/jeff/Downloads/download.pdf:pdf},
issn = {0733-8716},
journal = {IEEE J. Sel. Areas Commun.},
month = {aug},
number = {6},
pages = {908--921},
title = {{Measurement and analysis of single-hop delay on an IP backbone network}},
url = {http://ieeexplore.ieee.org/document/1217277/},
volume = {21},
year = {2003}
}
@article{Sugiyama2013,
author = {Sugiyama, Masashi and Liu, Song and Christoffel, Marthinus},
file = {:home/jeff/Downloads/Direct Divergence Approximation between Probability Distributions and Its Applications in Machine Learning.pdf:pdf},
keywords = {kullback-leibler divergence,l 2 -,machine learning,pearson divergence,probability distributions},
number = {2},
pages = {99--111},
title = {{Direct Divergence Approximation between Probability}},
volume = {7},
year = {2013}
}
@article{Chen2021,
abstract = {Network traffic classification that is widely applicable and highly accurate is valuable for many network security and management tasks. A flexible and easily configurable classification framework is ideal, as it can be customized for use in a wide variety of networks. In this paper, we propose a highly configurable and flexible machine learning traffic classification method that relies only on statistics of sequences of packets to distinguish known, or approved, traffic from unknown traffic. Our method is based on likelihood estimation, provides a measure of certainty for classification decisions, and can classify traffic at adjustable certainty levels. Our classification method can also be applied in different classification scenarios, each prioritizing a different classification goal. We demonstrate how our classification scheme and all its configurations perform well on real-world traffic from a high performance computing network environment.},
archivePrefix = {arXiv},
arxivId = {2107.06080},
author = {Chen, Jiahui and Breen, Joe and Phillips, Jeff M. and {Van der Merwe}, Jacobus},
doi = {10.1007/s10586-021-03393-2},
eprint = {2107.06080},
file = {:home/jeff/Downloads/2107.06080v1.pdf:pdf},
issn = {15737543},
journal = {Cluster Comput.},
keywords = {Network traffic classification,Science DMZ,Unknown detection},
title = {{Practical and configurable network traffic classification using probabilistic machine learning}},
year = {2021}
}
@article{Pathmaperuma2022,
abstract = {Despite the widespread use of encryption techniques to provide confidentiality over Internet communications, mobile device users are still susceptible to privacy and security risks. In this paper, a new Deep Neural Network (DNN) based user activity detection framework is proposed to identify fine grained user activities performed on mobile applications (known as in-app activities) from a sniffed encrypted Internet traffic stream. One of the challenges is that there are countless applications, and it is practically impossible to collect and train a DNN model using all possible data from them. Therefore, in this work we exploit the probability distribution of DNN output layer to filter the data from applications that are not considered during the model training (i.e., unknown data). The proposed framework uses a time window based approach to divide the traffic flow of an activity into segments, so that in-app activities can be identified just by observing only a fraction of the activity related traffic. Our tests have shown that the DNN based framework has demonstrated an accuracy of 90{\%} or above in identifying previously trained in-app activities and an average accuracy of 79{\%} in identifying previously untrained in-app activity traffic as unknown data when this framework is employed.},
archivePrefix = {arXiv},
arxivId = {2203.15501},
author = {Pathmaperuma, Madushi H. and Rahulamathavan, Yogachandran and Dogan, Safak and Kondoz, Ahmet M. and Lu, Rongxing},
eprint = {2203.15501},
file = {:home/jeff/Downloads/2203.15501v1.pdf:pdf},
keywords = {Deep Neural Network,Index Terms-Encrypted Traffic Classification,Mobile Data,Network Analysis},
title = {{Deep Learning for Encrypted Traffic Classification and Unknown Data Detection}},
url = {http://arxiv.org/abs/2203.15501},
year = {2022}
}
@article{Zhang2007,
abstract = {Delay is one of the network performance parameters that are often measured using passive or active techniques along with packet loss, bandwidth, etc. If used appropriately, these parameters can indicate performance status of the network, and they can be used in fault and performance management, network provisioning, traffic engineering, and performance prediction. However, it is difficult to extract sufficient information from original measurement data to derive precise results. In this paper, we show that the CDF (probability distribution function) of delay data can indicate network load situation. We also show that Pareto distribution can model end-to-end delay appropriately in a statistical manner and demonstrate some statistical characteristics of end-to-end delay using Pareto distribution. {\textcopyright} 2007 IEEE.},
author = {Zhang, Wei and He, Jingsha},
doi = {10.1109/ICIMP.2007.26},
isbn = {0769529119},
journal = {Second Int. Conf. Internet Monit. Prot. ICIMP 2007},
keywords = {Delay model,Network measurement,Pareto distribution},
title = {{Modeling end-to-end delay using pareto distribution}},
year = {2007}
}
@misc{zipf_web2,
title = {{Zipf, Power-law, Pareto - a ranking tutorial}},
url = {https://www.hpl.hp.com/research/idl/papers/ranking/ranking.html},
urldate = {2022-05-17}
}
@article{Pickands1975,
abstract = {A method is presented for making statistical inferences about the upper tail of a distribution function. It is useful for estimating the probabilities of future extremely large observations. The method is applicable if the underlying distribution function satisfies a condition which holds for all common continuous distribution functions.},
author = {III, James Pickands},
doi = {10.1214/aos/1176343003},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/III - 1975 - Statistical Inference Using Extreme Order Statistics(2).pdf:pdf},
issn = {0090-5364},
journal = {Ann. Stat.},
keywords = {Extreme order statistics,Extreme values,generalized Pareto function,upper tail},
month = {jan},
number = {1},
pages = {119--131},
publisher = {Institute of Mathematical Statistics},
title = {{Statistical Inference Using Extreme Order Statistics}},
url = {https://projecteuclid.org/journals/annals-of-statistics/volume-3/issue-1/Statistical-Inference-Using-Extreme-Order-Statistics/10.1214/aos/1176343003.full},
volume = {3},
year = {1975}
}
@article{Pacheco2019,
abstract = {Traffic analysis is a compound of strategies intended to find relationships, patterns, anomalies, and misconfigurations, among others things, in Internet traffic. In particular, traffic classification is a subgroup of strategies in this field that aims at identifying the application's name or type of Internet traffic. Nowadays, traffic classification has become a challenging task due to the rise of new technologies, such as traffic encryption and encapsulation, which decrease the performance of classical traffic classification strategies. Machine learning (ML) gains interest as a new direction in this field, showing signs of future success, such as knowledge extraction from encrypted traffic, and more accurate Quality of Service management. ML is fast becoming a key tool to build traffic classification solutions in real network traffic scenarios; in this sense, the purpose of this investigation is to explore the elements that allow this technique to work in the traffic classification field. Therefore, a systematic review is introduced based on the steps to achieve traffic classification by using ML techniques. The main aim is to understand and to identify the procedures followed by the existing works to achieve their goals. As a result, this survey paper finds a set of trends derived from the analysis performed on this domain; in this manner, the authors expect to outline future directions for ML-based traffic classification.},
author = {Pacheco, Fannia and Exposito, Ernesto and Gineste, Mathieu and Baudoin, Cedric and Aguilar, Jose},
doi = {10.1109/COMST.2018.2883147},
file = {:home/jeff/Downloads/COMST2883147.pdf:pdf},
issn = {1553-877X},
journal = {IEEE Commun. Surv. Tutorials},
keywords = {Internet traffic,machine learning,traffic classification,traffic monitoring},
number = {2},
pages = {1988--2014},
title = {{Towards the Deployment of Machine Learning Solutions in Network Traffic Classification: A Systematic Survey}},
url = {https://ieeexplore.ieee.org/document/8543584/},
volume = {21},
year = {2019}
}
@article{Nguyen2008,
abstract = {The research community has begun looking for IP traffic classification techniques that do not rely on 'well known' TCP or UDP port numbers, or interpreting the contents of packet payloads. New work is emerging on the use of statistical traffic characteristics to assist in the identification and classification process. This survey paper looks at emerging research into the application of Machine Learning (ML) techniques to IP traffic classification - an inter-disciplinary blend of IP networking and data mining techniques. We provide context and motivation for the application of ML techniques to IP traffic classification, and review 18 significant works that cover the dominant period from 2004 to early 2007. These works are categorized and reviewed according to their choice of ML strategies and primary contributions to the literature. We also discuss a number of key requirements for the employment of ML-based traffic classifiers in operational IP networks, and qualitatively critique the extent to which the reviewed works meet these requirements. Open issues and challenges in the field are also discussed. {\textcopyright} 2008 IEEE.},
author = {Nguyen, Thuy T.T. and Armitage, Grenville},
doi = {10.1109/SURV.2008.080406},
file = {:home/jeff/Downloads/LectureMLfortrafficclassification91917.pdf:pdf},
issn = {1553877X},
journal = {IEEE Commun. Surv. Tutorials},
keywords = {Flow clustering,Internet protocol,Machine learning,Payload inspection,Real time,Statistical traffic properties,Traffic classification},
number = {4},
pages = {56--76},
title = {{A survey of techniques for internet traffic classification using machine learning}},
volume = {10},
year = {2008}
}
@article{Shmatikov2006,
abstract = {Mix networks are a popular mechanism for anonymous Internet communications. By routing IP traffic through an overlay chain of mixes, they aim to hide the relationship between its origin and destination. Using a realistic model of interactive Internet traffic, we study the problem of defending low-latency mix networks against attacks based on correlating inter-packet intervals on two or more links of the mix chain. We investigate several attack models, including an active attack which involves adversarial modification of packet flows in order to "fingerprint" them, and analyze the tradeoffs between the amount of cover traffic, extra latency, and anonymity properties of the mix network. We demonstrate that previously proposed defenses are either ineffective, or impose a prohibitively large latency and/or bandwidth overhead on communicating applications. We propose a new defense based on adaptive padding. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
author = {Shmatikov, Vitaly and Wang, Ming Hsiu},
doi = {10.1007/11863908_2},
file = {:home/jeff/Downloads/shmat{\_}esorics06.pdf:pdf},
isbn = {354044601X},
issn = {16113349},
journal = {Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)},
pages = {18--33},
title = {{Timing analysis in low-latency mix networks: Attacks and defenses}},
volume = {4189 LNCS},
year = {2006}
}
@inproceedings{Tsai1987,
abstract = {A formal method for the identification of covert storage channels is presented and its application to the source code of the Secure Xenix kernel is illustrated. The method is based on the identification of all visible/alterable kernel variables by using information flow analysis of language code (e. g. , C language code). The method also requires that, after the sharing relationships among the kernel primitives and the visible/alterable variables are determined, the nondiscretionary access rules implemented by each primitive be applied to identify the covert storage channels. The method can be generalized to other implementation languages, and has the following advantages: (1) it leads to the discovery of all storage channels in kernel implementations; (2) it helps determine whether the nondiscretionary access rules are implemented correctly; and (3) it can be automated. An additional important aspect of applying this method to a kernel interface is the discovery of all kernel variables that are modified directly or indirectly through that interface.},
author = {Tsai, Chii-Ren and Gligor, Virgil D. and Chandersekaran, C. Sekar},
booktitle = {1987 IEEE Symp. Secur. Priv.},
doi = {10.1109/SP.1987.10014},
isbn = {0-8186-0771-8},
month = {apr},
pages = {74--74},
publisher = {IEEE},
title = {{A Formal Method for the Identification of Covert Storage Channels in Source Code}},
url = {http://ieeexplore.ieee.org/document/6234878/},
year = {1987}
}
@article{Pfitzinger2019,
abstract = {Complementing a recently collected large data set on the TCP connection termination latency in GPRS networks we analyze server-side log data generated in a large scale automatic toll system to observe the network bandwidth. After a recent architectural change the on-board units (OBUs) record GPS tracks and transmit track data to the central system for processing rather than transmitting the toll data after local processing. The bandwidth in upload direction is estimated from the server-side log entries and corrected for the network latency. The data collected allows comparing the performance of seven types of OBUs in three GPRS networks over time. While the three networks differ in the average bandwidth offered, the biggest performance impact is the OBU type where modems with the same specification yield different upload rates. In addition we update the GPRS network latency data by fitting two statistical distributions, improving markedly on the prior results.},
author = {Pfitzinger, Bernd and Baumann, Tommy and Emde, Andreas and Gr{\"{u}}nder, Torsten and Macos, Dragan and Jest{\"{a}}dt, Thomas},
doi = {10.24251/HICSS.2019.906},
file = {:home/jeff/Downloads/Network-Wide{\_}Measurement{\_}of{\_}GPRS{\_}Bandwidth{\_}and{\_}Lat.pdf:pdf},
isbn = {9780998133126},
issn = {15301605},
journal = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
pages = {7521--7528},
publisher = {IEEE Computer Society},
title = {{Network-wide measurement of GPRS bandwidth and latency}},
volume = {2019-Janua},
year = {2019}
}
@misc{ml_web1,
title = {{The Actual Difference Between Statistics and Machine Learning | by Matthew Stewart, PhD Researcher | Towards Data Science}},
url = {https://towardsdatascience.com/the-actual-difference-between-statistics-and-machine-learning-64b49f07ea3},
urldate = {2022-05-27}
}
@article{Sussmann1997,
abstract = {The uncertainty area $\delta$ (p, q): - [∫ W(p, q) 2 dp dq] - 1 is proposed in place of $\delta$ p • $\delta$ q, and it is shown that each pure quantum state is a minimum uncertainty state in this sense: $\delta$ (p, q) = 2 $\pi$ ħ. For mixed states, on the other hand, $\delta$(p, q) {\textgreater} 2$\pi$ ħ. In a phase space of 2F(=6N) dimensions, S: = k B • log[$\delta$ F (p,q)/(2 $\pi$ ħ) F ] whit $\delta$ F (p,q):= [∫ W(p, q) 2 d F p d F q] -1 is considered as an alternative to von Neumann`s entropy S̃:= k B • trc [$\rho$̂ log ($\rho$̂ -1 )].},
author = {S{\"{u}}ssmann, Georg},
doi = {10.1515/zna-1997-1-214},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/S{\"{u}}ssmann - 1997 - Uncertainty relation From inequality to equality.pdf:pdf},
issn = {1865-7109},
journal = {Zeitschrift f{\"{u}}r Naturforsch. A},
month = {feb},
number = {1-2},
pages = {49--52},
publisher = {Verlag der Zeitschrift fur Naturforschung},
title = {{Uncertainty Relation: From Inequality to Equality}},
url = {https://www.degruyter.com/document/doi/10.1515/zna-1997-1-214/html},
volume = {52},
year = {1997}
}
@article{Corral2015,
abstract = {Zipf's law is a fundamental paradigm in the statistics of written and spoken natural language as well as in other communication systems. We raise the question of the elementary units for which Zipf's law should hold in the most natural way, studying its validity for plain word forms and for the corresponding lemma forms. We analyze several long literary texts comprising four languages, with different levels of morphological complexity. In all cases Zipf's law is fulfilled, in the sense that a power-law distribution of word or lemma frequencies is valid for several orders of magnitude. We investigate the extent to which the word-lemma transformation preserves two parameters of Zipf's law: the exponent and the low-frequency cut-off. We are not able to demonstrate a strict invariance of the tail, as for a few texts both exponents deviate significantly, but we conclude that the exponents are very similar, despite the remarkable transformation that going from words to lemmas represents, considerably affecting all ranges of frequencies. In contrast, the low-frequency cut-offs are less stable, tending to increase substantially after the transformation.},
author = {Corral, {\'{A}}lvaro and Boleda, Gemma and Ferrer-i-Cancho, Ramon},
doi = {10.1371/journal.pone.0129031},
editor = {Jiang, Bin},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Corral, Boleda, Ferrer-i-Cancho - 2015 - Zipf's Law for Word Frequencies Word Forms versus Lemmas in Long Texts.pdf:pdf},
issn = {1932-6203},
journal = {PLoS One},
keywords = {Computational linguistics,Covariance,Languages,Linguistic morphology,Linguistics,Monte Carlo method,Semantics,Vocabulary},
month = {jul},
number = {7},
pages = {e0129031},
publisher = {Public Library of Science},
title = {{Zipf's Law for Word Frequencies: Word Forms versus Lemmas in Long Texts}},
url = {https://dx.plos.org/10.1371/journal.pone.0129031},
volume = {10},
year = {2015}
}
@article{Yang2015,
author = {Yang, Jian Bo and Nguyen, Minh Nhut and San, Phyo Phyo and Li, Xiao Li and Krishnaswamy, Shonali},
file = {:home/jeff/Downloads/561.pdf:pdf},
keywords = {Special Track on Machine Learning},
number = {Ijcai},
pages = {3995--4001},
title = {{Deep Convolutional Neural Networks On Multichannel Time Series For Human Activity Recognition}},
year = {2015}
}
@article{Wuest2016,
abstract = {The nature of manufacturing systems faces ever more complex, dynamic and at times even chaotic behaviors. In order to being able to satisfy the demand for high-quality products in an efficient manner, it is essential to utilize all means available. One area, which saw fast pace developments in terms of not only promising results but also usability, is machine learning. Promising an answer to many of the old and new challenges of manufacturing, machine learning is widely discussed by researchers and practitioners alike. However, the field is very broad and even confusing which presents a challenge and a barrier hindering wide application. Here, this paper contributes in presenting an overview of available machine learning techniques and structuring this rather complicated area. A special focus is laid on the potential benefit, and examples of successful applications in a manufacturing environment.},
author = {Wuest, Thorsten and Weimer, Daniel and Irgens, Christopher and Thoben, Klaus Dieter},
doi = {10.1080/21693277.2016.1192517},
file = {:home/jeff/Downloads/Machine learning in manufacturing advantages challenges and applications.pdf:pdf},
issn = {21693277},
journal = {Prod. Manuf. Res.},
keywords = {Intelligent manufacturing systems,Machine learning,Manufacturing,Smart manufacturing},
number = {1},
pages = {23--45},
publisher = {Taylor {\&} Francis},
title = {{Machine learning in manufacturing: Advantages, challenges, and applications}},
url = {http://dx.doi.org/10.1080/21693277.2016.1192517},
volume = {4},
year = {2016}
}
@article{Elguea2017a,
abstract = {Comparing two or more routes on Internet is difficult owing to the variability of the measurements resulting from the different routes or use conditions. With current tools such as SDN[1], it is important to determine with certainty which the best route between a user and an internet service. This will be achieved with fast measurements which do not affect the operation of the network. With trends such as IoT, the best routes can be identified based on latency and not just on the jumps between autonomous systems, fact that optimizes data traffic in a specific way whether it is IPv4 or IPv6. As time elapses, it becomes more important to have a perfect setting for the LAN, which means optimal DNS, LDAP Servers appropriate number, etc. Thats why we propose a precise method that contemplates every possible variation of data, thus making a comparison by means of the use of confidence limits.},
author = {Elguea, Lorenzo M. and Martinez-Rios, Felix},
doi = {10.1016/j.procs.2017.10.076},
file = {:home/jeff/Downloads/1-s2.0-S1877050917321269-main(1).pdf:pdf},
isbn = {9781510849914},
issn = {18770509},
journal = {Procedia Comput. Sci.},
keywords = {BGP,Compare,Latency,SDN,Statistics,Variance},
pages = {393--400},
publisher = {Elsevier B.V.},
title = {{An efficient method to compare latencies in order to obtain the best route for SDN}},
url = {https://doi.org/10.1016/j.procs.2017.10.076},
volume = {116},
year = {2017}
}
@inproceedings{Pfitzinger2018,
abstract = {We analyze existing server-side log data of a large scale automatic toll system to measure the TCP round-trip-time (RTT) as experienced by the communication between the central system and the on-board units (OBUs) deployed for tolling heavy-goods vehicles. The RTT is estimated from passive monitoring by parsing server-side log files and aggregating fleet-wide statistics over time. Using this data we compare the characteristics of the four different types of OBU and the three GPRS (2G) networks used. We find the RTT data to be consistent with existing, smaller samples and extend the observed RTT range by an order of magnitude. The OBU types exhibit a markedly different behavior, most notably for long RTTs, and we find one of the 2G networks to ‘hum' at 50 Hz and harmonics.},
author = {Pfitzinger, Bernd and Baumann, Tommy and Emde, Andreas and Macos, Dragan and Jest{\"{a}}dt, Thomas},
booktitle = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
doi = {10.24251/HICSS.2018.729},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pfitzinger et al. - 2018 - Network-wide measurement of TCP RTT in 2G networks.pdf:pdf},
isbn = {9780998133119},
issn = {15301605},
pages = {5818--5824},
publisher = {IEEE Computer Society},
title = {{Network-wide Measurement of TCP RTT in 2G Networks}},
url = {http://hdl.handle.net/10125/50618},
volume = {2018-Janua},
year = {2018}
}
@misc{keras,
author = {Chollet, Fran{\'{c}}ois},
title = {{Keras}},
url = {https://keras.io},
year = {2015}
}
@article{Cooke2011,
author = {Cooke, Roger M and Nieboer, Daan},
doi = {10.2139/ssrn.1811043},
file = {:home/jeff/Downloads/RFF-DP-11-19.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electron. J.},
title = {{Heavy-Tailed Distributions: Data, Diagnostics, and New Developments}},
url = {http://www.ssrn.com/abstract=1811043},
year = {2011}
}
@article{Kocisk2014,
author = {Kocisky, Michal and Lasz, Jozef and Kotuliak, Ivan},
doi = {10.2498/cit.1000878},
file = {:home/jeff/Downloads/Analysis{\_}of{\_}Ethernet{\_}Traffic{\_}Statistical{\_}Propertie.pdf:pdf},
issn = {1330-1136},
journal = {J. Comput. Inf. Technol.},
keywords = {2,form,hurst parameter,in,lrd,properties of the traffic,s approach,self-similarity,similar study,srd,traffic profile,was presented using r,wavelet trans-,we prefer},
number = {1},
pages = {15},
title = {{Analysis of Ethernet Traffic Statistical Properties}},
url = {http://cit.srce.unizg.hr/index.php/CIT/article/view/1655},
volume = {16},
year = {2008}
}
@inproceedings{Schmidbauer2021,
abstract = {The appearance of novel ideas for network covert channels leads to an urge for developing new detection approaches. One of these new ideas are reversible network covert channels that are able to restore the original overt information without leaving any direct evidence of their appearance. Some of these reversible covert channels are based upon computational intensive operations, like for example encoding hidden information in the authentication hashes of a hash chain based one-time password. For such a covert channel implementation, the hash function has to be called repeatedly to extract the hidden message and to restore the original information. In this paper, we investigate the influence of repeated MD5 and SHA3 hash operations on the runtime of an authentication request-response. We first define two alphabets, one which leads to the fewest hash operations and one which leads to the most hash operations to be performed. Further, for each alphabet, we carry out three experiments. One without a covert channel, one with a covert channel altering all hashes, and finally, one with a covert channel altering every second hash. We further investigate the detection rates of computational intensive reversible covert channels for all scenarios by applying a threshold-based detection upon the average packet runtime without encoded covert information. Finally, we describe countermeasures and the limitations of this detection approach.},
address = {New York, NY, USA},
author = {Schmidbauer, Tobias and Wendzel, Steffen},
booktitle = {16th Int. Conf. Availability, Reliab. Secur.},
doi = {10.1145/3465481.3470085},
file = {:home/jeff/Desktop/SynologyDrive/projekte/Bachelor/papers/hunting shadows/71{\_}Hunting Shadows Towards Packet Runtime-based Detection Of Computational Intensive Reversible Covert Channels.pdf:pdf},
isbn = {9781450390514},
keywords = {Main,OTP,anomaly detection,covert channel,hash chains,network security,network steganography,reversible steganography},
mendeley-tags = {Main},
month = {aug},
pages = {1--10},
publisher = {ACM},
title = {{Hunting Shadows: Towards Packet Runtime-based Detection Of Computational Intensive Reversible Covert Channels}},
url = {https://dl.acm.org/doi/10.1145/3465481.3470085},
year = {2021}
}
@article{Dempster2021,
abstract = {Rocket achieves state-of-the-art accuracy for time series classification with a fraction of the computational expense of most existing methods by transforming input time series using random convolutional kernels, and using the transformed features to train a linear classifier. We reformulate Rocket into a new method, MiniRocket. MiniRocket is up to 75 times faster than Rocket on larger datasets, and almost deterministic (and optionally, fully deterministic), while maintaining essentially the same accuracy. Using this method, it is possible to train and test a classifier on all of 109 datasets from the UCR archive to state-of-the-art accuracy in under 10 minutes. MiniRocket is significantly faster than any other method of comparable accuracy (including Rocket), and significantly more accurate than any other method of remotely similar computational expense.},
archivePrefix = {arXiv},
arxivId = {2012.08791},
author = {Dempster, Angus and Schmidt, Daniel F. and Webb, Geoffrey I.},
doi = {10.1145/3447548.3467231},
eprint = {2012.08791},
isbn = {9781450383325},
journal = {Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.},
keywords = {convolution,scalable,time series classification,transform},
month = {aug},
pages = {248--257},
publisher = {Association for Computing Machinery},
title = {{MiniRocket: A Very Fast (Almost) Deterministic Transform for Time Series Classification}},
year = {2021}
}
@article{Olsavszky2020,
abstract = {The application of machine learning (ML) for use in generating insights and making predictions on new records continues to expand within the medical community. Despite this progress to date, the application of time series analysis has remained underexplored due to complexity of the underlying techniques. In this study, we have deployed a novel ML, called automated time series (AutoTS) machine learning, to automate data processing and the application of a multitude of models to assess which best forecasts future values. This rapid experimentation allows for and enables the selection of the most accurate model in order to perform time series predictions. By using the nation-wide ICD-10 (International Classification of Diseases, Tenth Revision) dataset of hospitalized patients of Romania, we have generated time series datasets over the period of 2008–2018 and performed highly accurate AutoTS predictions for the ten deadliest diseases. Forecast results for the years 2019 and 2020 were generated on a NUTS 2 (Nomenclature of Territorial Units for Statistics) regional level. This is the first study to our knowledge to perform time series forecasting of multiple diseases at a regional level using automated time series machine learning on a national ICD-10 dataset. The deployment of AutoTS technology can help decision makers in implementing targeted national health policies more efficiently.},
author = {Olsavszky, Victor and Dosius, Mihnea and Benecke, Johannes and Vladescu, Cristian},
doi = {10.3390/ijerph17144979},
file = {:home/jeff/Desktop/SynologyDrive/projekte/Bachelor/papers/ijerph-17-04979-v2.pdf:pdf},
issn = {16604601},
journal = {Int. J. Environ. Res. Public Health},
keywords = {Artificial intelligence,Automated machine learning,Deadliest diseases,Deep learning,Disease prediction,Interesting,Novel,Time series},
mendeley-tags = {Interesting,Novel},
number = {14},
pages = {1--17},
pmid = {32664331},
title = {{Time series analysis and forecasting with automated machine learning on a national ICD-10 database}},
volume = {17},
year = {2020}
}
@article{Saeli2020,
abstract = {Detecting covert channels among legitimate traffic represents a severe challenge due to the high heterogeneity of networks. Therefore, we propose an effective covert channel detection method, based on the analysis of DNS network data passively extracted from a network monitoring system. The framework is based on a machine learning module and on the extraction of specific anomaly indicators able to describe the problem at hand. The contribution of this paper is two-fold: (i) the machine learning models encompass network profiles tailored to the network users, and not to the single query events, hence allowing for the creation of behavioral profiles and spotting possible deviations from the normal baseline; (ii) models are created in an unsupervised mode, thus allowing for the identification of zero-days attacks and avoiding the requirement of signatures or heuristics for new variants. The proposed solution has been evaluated over a 15-day-long experimental session with the injection of traffic that covers the most relevant exfiltration and tunneling attacks: all the malicious variants were detected, while producing a low false-positive rate during the same period.},
archivePrefix = {arXiv},
arxivId = {2010.01582},
author = {Saeli, Salvatore and Bisio, Federica and Lombardo, Pierangelo and Massa, Danilo},
eprint = {2010.01582},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saeli et al. - 2020 - DNS Covert Channel Detection via Behavioral Analysis a Machine Learning Approach.pdf:pdf},
month = {oct},
title = {{DNS Covert Channel Detection via Behavioral Analysis: a Machine Learning Approach}},
url = {http://arxiv.org/abs/2010.01582},
year = {2020}
}
@article{Kirichenko2020,
author = {Kirichenko, Lyudmyla and Radivilova, Tamara},
doi = {10.1007/978-3-030-26474-1},
file = {:home/jeff/Downloads/KirichenkoL.pdf:pdf},
isbn = {9783030264741},
number = {January},
title = {{Binary Classification of Fractal Time Series by Machine Learning Methods}},
year = {2020}
}
@book{Mazurczyk2016,
author = {Mazurczyk;, Wojciech and Wendzel, Steffen and Zander, Sebastian and Houmansadr, Amir and Szczypiorski, Krzysztof},
title = {{Information Hiding in Communication Networks: Fundamentals, Mechanisms, Applications, and Countermeasures | IEEE eBooks | IEEE Xplore}},
url = {https://ieeexplore.ieee.org/book/7434879},
year = {2016}
}
@article{Mann1947,
abstract = {Let {\$}x{\$} and {\$}y{\$} be two random variables with continuous cumulative distribution functions {\$}f{\$} and {\$}g{\$}. A statistic {\$}U{\$} depending on the relative ranks of the {\$}x{\$}'s and {\$}y{\$}'s is proposed for testing the hypothesis {\$}f = g{\$}. Wilcoxon proposed an equivalent test in the Biometrics Bulletin, December, 1945, but gave only a few points of the distribution of his statistic. Under the hypothesis {\$}f = g{\$} the probability of obtaining a given {\$}U{\$} in a sample of {\$}n x's{\$} and {\$}m y's{\$} is the solution of a certain recurrence relation involving {\$}n{\$} and {\$}m{\$}. Using this recurrence relation tables have been computed giving the probability of {\$}U{\$} for samples up to {\$}n = m = 8{\$}. At this point the distribution is almost normal. From the recurrence relation explicit expressions for the mean, variance, and fourth moment are obtained. The 2rth moment is shown to have a certain form which enabled us to prove that the limit distribution is normal if {\$}m, n{\$} go to infinity in any arbitrary manner. The test is shown to be consistent with respect to the class of alternatives {\$}f(x) {\textgreater} g(x){\$} for every {\$}x{\$}.},
author = {Mann, H. B. and Whitney, D. R.},
doi = {10.1214/aoms/1177730491},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mann, Whitney - 1947 - On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other.pdf:pdf},
issn = {0003-4851},
journal = {Ann. Math. Stat.},
month = {mar},
number = {1},
pages = {50--60},
publisher = {Institute of Mathematical Statistics},
title = {{On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other}},
url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-18/issue-1/On-a-Test-of-Whether-one-of-Two-Random-Variables/10.1214/aoms/1177730491.full https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-18/issue-1/On-},
volume = {18},
year = {1947}
}
@article{Wen2021,
abstract = {Deep learning performs remarkably well on many time series analysis tasks recently. The superior performance of deep neural networks relies heavily on a large number of training data to avoid overfitting. However, the labeled data of many real-world time series applications may be limited such as classification in medical time series and anomaly detection in AIOps. As an effective way to enhance the size and quality of the training data, data augmentation is crucial to the successful application of deep learning models on time series data. In this paper, we systematically review different data augmentation methods for time series. We propose a taxonomy for the reviewed methods, and then provide a structured review for these methods by highlighting their strengths and limitations. We also empirically compare different data augmentation methods for different tasks including time series classification, anomaly detection, and forecasting. Finally, we discuss and highlight five future directions to provide useful research guidance.},
archivePrefix = {arXiv},
arxivId = {2002.12478},
author = {Wen, Qingsong and Sun, Liang and Yang, Fan and Song, Xiaomin and Gao, Jingkun and Wang, Xue and Xu, Huan},
doi = {10.24963/IJCAI.2021/631},
eprint = {2002.12478},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wen et al. - 2021 - Time Series Data Augmentation for Deep Learning A Survey.pdf:pdf},
isbn = {9780999241196},
issn = {10450823},
month = {aug},
pages = {4653--4660},
publisher = {International Joint Conferences on Artificial Intelligence},
title = {{Time Series Data Augmentation for Deep Learning: A Survey}},
year = {2021}
}
@article{Fei1998,
abstract = {To nd out how big the Internet is, we measured the round-trip delays and hop-counts from a UCLA host computer to a randomly selected set of three thousand Internet hosts around the world. Our results show that over 90{\%} of these hosts in continental US are within 18 hops from UCLA, and the round-trip delays to 90{\%} of these hosts are less than 153ms. There seems no strong correlation between the delay and hop-count, although the average delay increases with hop-count. Measure-ments to international hosts show that the delay and hop-count strongly depend on the countries the hosts locate. Physical distances and link speeds are the most important factors that determine the round-trip delay.},
author = {Fei, Aiguo and Pei, Guangyu and Liu, Roy and Zhang, Lixia},
file = {:home/jeff/Downloads/10.1.1.30.6547.pdf:pdf},
journal = {Proc. 1998 IEEE Glob. Telecommun. Conf. (IEEE GLOBECOM'98)},
number = {September},
title = {{Measurements on delay and hop-count of the internet}},
url = {https://pdfs.semanticscholar.org/5e21/0949a3bcf4c9e1f71208a53311e553628582.pdf},
year = {1998}
}
@article{Lamport,
abstract = {A method of user password authentication is described which is secure even if an intruder can read the system's data, and can tamper with or eavesdrop on the communication between the user and the system. The method assumes a secure one-way encryption function and can be implemented with a microcomputer in the user's terminal.},
author = {Lamport, Leslie},
doi = {10.1145/358790.358797},
file = {:home/jeff/Downloads/password.pdf:pdf},
issn = {0001-0782},
journal = {Commun. ACM},
keywords = {authentication,one-way function,passwords,security},
month = {nov},
number = {11},
pages = {770--772},
title = {{Password authentication with insecure communication}},
url = {https://dl.acm.org/doi/10.1145/358790.358797},
volume = {24},
year = {1981}
}
@article{Kaheman2022,
abstract = {The sparse identification of nonlinear dynamics (SINDy) is a regression framework for the discovery of parsimonious dynamic models and governing equations from time-series data. As with all system identification methods, noisy measurements compromise the accuracy and robustness of the model discovery procedure. In this work we develop a variant of the SINDy algorithm that integrates automatic differentiation and recent time-stepping constrained motivated by Rudy et al (2019 J. Computat. Phys. 396 483-506) for simultaneously (1) denoising the data, (2) learning and parametrizing the noise probability distribution, and (3) identifying the underlying parsimonious dynamical system responsible for generating the time-series data. Thus within an integrated optimization framework, noise can be separated from signal, resulting in an architecture that is approximately twice as robust to noise as state-of-the-art methods, handling as much as 40{\%} noise on a given time-series signal and explicitly parametrizing the noise probability distribution. We demonstrate this approach on several numerical examples, from Lotka-Volterra models to the spatio-temporal Lorenz 96 model. Further, we show the method can learn a diversity of probability distributions for the measurement noise, including Gaussian, uniform, Gamma, and Rayleigh distributions.},
archivePrefix = {arXiv},
arxivId = {2009.08810},
author = {Kaheman, Kadierdan and Brunton, Steven L. and {Nathan Kutz}, J.},
doi = {10.1088/2632-2153/ac567a},
eprint = {2009.08810},
file = {:home/jeff/Downloads/Kaheman{\_}2022{\_}Mach.{\_}Learn. {\_}Sci.{\_}Technol.{\_}3{\_}015031.pdf:pdf},
issn = {26322153},
journal = {Mach. Learn. Sci. Technol.},
keywords = {automatic differentiation,denoising,discrepancy modeling,machine learning,nonlinear dynamics,optimization,sparse identification},
number = {1},
title = {{Automatic differentiation to simultaneously identify nonlinear dynamics and extract noise probability distributions from data}},
volume = {3},
year = {2022}
}
@article{Gianvecchio2007,
abstract = {The detection of covert timing channels is of increasing interest in light of recent practice on the exploitation of covert timing channels over the Internet. However, due to the high variation in legitimate network traffic, detecting covert timing channels is a challenging task. The existing detection schemes are ineffective to detect most of the covert timing channels known to the security community. In this paper, we introduce a new entropy-based approach to detecting various covert timing channels. Our new approach is based on the observation that the creation of a covert timing channel has certain effects on the entropy of the original process, and hence, a change in the entropy of a process provides a critical clue for covert timing channel detection. Exploiting this observation, we investigate the use of entropy and conditional entropy in detecting covert timing channels. Our experimental results show that our entropy-based approach is sensitive to the current covert timing channels, and is capable of detecting them in an accurate manner. Copyright 2007 ACM.},
author = {Gianvecchio, Steven and Wang, Haining},
doi = {10.1145/1315245.1315284},
isbn = {9781595937032},
issn = {15437221},
journal = {Proc. ACM Conf. Comput. Commun. Secur.},
keywords = {Covert timing channels,Detection},
pages = {307--316},
title = {{Detecting covert timing channels: An entropy-based approach}},
year = {2007}
}
@article{Lampson1973,
abstract = {onfining a program during its execution so that it cannot transmit information to any other program except its caller. A set of examples attempts to stake out the boundaries of the problem. Necessary conditions for a solution are stated and informally justified.},
author = {Lampson, Butler W.},
doi = {10.1145/362375.362389},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lampson - 1973 - A Note on the Confinement Problem.pdf:pdf},
issn = {0001-0782},
journal = {Commun. ACM},
keywords = {confinement,leakage of data,privacy,proprietary program,protection,security},
month = {oct},
number = {10},
pages = {613--615},
title = {{A note on the confinement problem}},
url = {https://dl.acm.org/doi/10.1145/362375.362389},
volume = {16},
year = {1973}
}
@phdthesis{Faouzi2022,
author = {Faouzi, Johann},
file = {:home/jeff/Downloads/Time Series Classification A review of Algorithms and Implementations.pdf:pdf},
isbn = {978-1-8381524-1-3},
title = {{Time Series Classification : A review of Algorithms and Implementations}},
year = {2022}
}
@article{Velasco-Mata2021,
abstract = {Botnets are one of the online threats with the most significant presence, causing billionaire losses to global economies. Nowadays, the increasing number of devices connected to the Internet makes it necessary to analyze extensive network traffic data. In this work, we focus on increasing the performance of botnet traffic classification by selecting those features that further increase the detection rate. For this purpose, we use two feature selection techniques, i.e., Information Gain and Gini Importance, which led to three pre-selected subsets of five, six and seven features. Then, we evaluate the three feature subsets and three models, i.e., Decision Tree, Random Forest and k-Nearest Neighbors. To test the performance of the three feature vectors and the three models, we generate two datasets based on the CTU-13 dataset, namely QB-CTU13 and EQB-CTU13. Finally, we measure the performance as the macro averaged F1 score over the computational time required to classify a sample. The results show that the highest performance is achieved by Decision Trees using a five feature set, which obtained a mean F1 score of 85{\%} classifying each sample in an average time of 0.78 microseconds.},
archivePrefix = {arXiv},
arxivId = {2107.02896},
author = {Velasco-Mata, Javier and Gonzalez-Castro, Victor and Fernandez, Eduardo Fidalgo and Alegre, Enrique},
doi = {10.1109/ACCESS.2021.3108222},
eprint = {2107.02896},
file = {:home/jeff/Downloads/2107.02896v1.pdf:pdf},
issn = {2169-3536},
journal = {IEEE Access},
keywords = {Computational and artificial intelligence,computer applications,decision trees,machine learning algorithms,optimization methods},
pages = {120567--120579},
title = {{Efficient Detection of Botnet Traffic by Features Selection and Decision Trees}},
url = {https://ieeexplore.ieee.org/document/9523853/},
volume = {9},
year = {2021}
}
@article{Bulakh2018,
abstract = {The article considers classification task of fractal time series by the meta algorithms based on decision trees. Binomial multiplicative stochastic cascades are used as input time series. Comparative analysis of the classification approaches based on different features is carried out. The results indicate the advantage of the machine learning methods over the traditional estimating the degree of self-similarity. Keywords},
author = {Bulakh, Vitalii and Kirichenko, Lyudmyla and Radivilova, Tamara},
file = {:home/jeff/Downloads/1905.03096.pdf:pdf},
keywords = {binomial stochastic,cascade,classification of time series,hurst exponent,multifractal time series,random},
title = {{Time series classification based on fractal properties 1}},
volume = {2},
year = {2018}
}
@article{Abramson1963,
author = {Abramson, N. and Braverman, D. and Sebestyen, G.},
doi = {10.1109/TIT.1963.1057854},
file = {:home/jeff/Downloads/bg0137-with-cover-page-v2.pdf:pdf},
issn = {15579654},
journal = {IEEE Trans. Inf. Theory},
number = {4},
pages = {257--261},
title = {{Pattern recognition and machine learning}},
volume = {9},
year = {1963}
}
@article{Pande2017,
author = {Pande, Hemlata and Dhami, H S},
file = {:home/jeff/Downloads/02.pdf:pdf},
keywords = {entropy,frequency,model,rank,s order,zipf},
pages = {19--38},
title = {{Mathematical Modelling of Occurrence of Letters and Word ' s Initials in Texts of Hindi Language}},
year = {2017}
}
@article{Gardes2004,
abstract = {One of the main goal of extreme value analysis is to estimate the probability of rare events given a sample from an unknown distribution. The upper tail behavior of this distribution is described by the extreme value index. We present a new estimator of the extreme value index adapted to any domain of attraction. Its construction is similar to the one of Pickands' estimator. its weak consistency and its asymptotic distribution are established and a bias reduction method is proposed. Our estimator is compared with classical extreme value index estimators through a simulation study.},
archivePrefix = {arXiv},
arxivId = {math/0403299},
author = {Gardes, Laurent and Girard, Stephane},
eprint = {0403299},
file = {:home/jeff/Downloads/math0403299.pdf:pdf},
keywords = {adaptive estimator,asymptotic,consistency,extreme value index,generalized pickands estimator,normality},
number = {April},
pages = {389--409},
primaryClass = {math},
title = {{A Pickands type estimator of the extreme value index}},
url = {http://arxiv.org/abs/math/0403299},
volume = {102},
year = {2004}
}
@article{Shahraki2022,
abstract = {Network Traffic Classification (NTC) has become an important feature in various network management operations, e.g., Quality of Service (QoS) provisioning and security services. Machine Learning (ML) algorithms as a popular approach for NTC can promise reasonable accuracy in classification and deal with encrypted traffic. However, ML-based NTC techniques suffer from the shortage of labeled traffic data which is the case in many real-world applications. This study investigates the applicability of an active form of ML, called Active Learning (AL), in NTC. AL reduces the need for a large number of labeled examples by actively choosing the instances that should be labeled. The study first provides an overview of NTC and its fundamental challenges along with surveying the literature on ML-based NTC methods. Then, it introduces the concepts of AL, discusses it in the context of NTC, and review the literature in this field. Further, challenges and open issues in AL-based classification of network traffic are discussed. Moreover, as a technical survey, some experiments are conducted to show the broad applicability of AL in NTC. The simulation results show that AL can achieve high accuracy with a small amount of data.},
archivePrefix = {arXiv},
arxivId = {2106.06933},
author = {Shahraki, Amin and Abbasi, Mahmoud and Taherkordi, Amir and Jurcut, Anca Delia},
doi = {10.1109/TCCN.2021.3119062},
eprint = {2106.06933},
file = {:home/jeff/Downloads/2106.06933v2.pdf:pdf},
issn = {2332-7731},
journal = {IEEE Trans. Cogn. Commun. Netw.},
keywords = {Active learning,Machine learning,NTMA,Network traffic classification,Survey},
month = {mar},
number = {1},
pages = {422--439},
title = {{Active Learning for Network Traffic Classification: A Technical Study}},
url = {https://ieeexplore.ieee.org/document/9566310/},
volume = {8},
year = {2022}
}
@article{LeNguyen2019,
abstract = {The time series classification literature has expanded rapidly over the last decade, with many new classification approaches published each year. Prior research has mostly focused on improving the accuracy and efficiency of classifiers, with interpretability being somewhat neglected. This aspect of classifiers has become critical for many application domains and the introduction of the EU GDPR legislation in 2018 is likely to further emphasize the importance of interpretable learning algorithms. Currently, state-of-the-art classification accuracy is achieved with very complex models based on large ensembles (COTE) or deep neural networks (FCN). These approaches are not efficient with regard to either time or space, are difficult to interpret and cannot be applied to variable-length time series, requiring pre-processing of the original series to a set fixed-length. In this paper we propose new time series classification algorithms to address these gaps. Our approach is based on symbolic representations of time series, efficient sequence mining algorithms and linear classification models. Our linear models are as accurate as deep learning models but are more efficient regarding running time and memory, can work with variable-length time series and can be interpreted by highlighting the discriminative symbolic features on the original time series. We advance the state-of-the-art in time series classification by proposing new algorithms built using the following three key ideas: (1) Multiple resolutions of symbolic representations: we combine symbolic representations obtained using different parameters, rather than one fixed representation (e.g., multiple SAX representations); (2) Multiple domain representations: we combine symbolic representations in time (e.g., SAX) and frequency (e.g., SFA) domains, to be more robust across problem types; (3) Efficient navigation in a huge symbolic-words space: we extend a symbolic sequence classifier (SEQL) to work with multiple symbolic representations and use its greedy feature selection strategy to effectively filter the best features for each representation. We show that our multi-resolution multi-domain linear classifier (mtSS-SEQL+LR) achieves a similar accuracy to the state-of-the-art COTE ensemble, and to recent deep learning methods (FCN, ResNet), but uses a fraction of the time and memory required by either COTE or deep models. To further analyse the interpretability of our classifier, we present a case study on a human motion dataset collected by the authors. We discuss the accuracy, efficiency and interpretability of our proposed algorithms and release all the results, source code and data to encourage reproducibility.},
archivePrefix = {arXiv},
arxivId = {2006.01667},
author = {{Le Nguyen}, Thach and Gsponer, Severin and Ilie, Iulia and O'Reilly, Martin and Ifrim, Georgiana},
doi = {10.1007/S10618-019-00633-3},
eprint = {2006.01667},
issn = {1573756X},
journal = {Data Min. Knowl. Discov.},
keywords = {Interpretable classifier,Linear models,Multi-resolution multi-domain symbolic representat,SAX,SEQL,SFA,Time series classification},
month = {jul},
number = {4},
pages = {1183--1222},
publisher = {Springer New York LLC},
title = {{Interpretable time series classification using linear models and multi-resolution multi-domain symbolic representations}},
volume = {33},
year = {2019}
}
@article{Moreira2022,
abstract = {This article presents Maximum Visibility Approach (MVA), a new time series forecasting method based on the Complex Network theory. MVA initially maps time series data into a complex network using the visibility graph method. Then, based on the similarity measures between the nodes in the network, MVA calculates the one-step-ahead forecasts. MVA does not use all past terms in the forecasting process, but only the most significant observations, which are indicated as a result of the autocorrelation function. This method was applied to five different groups of data, most of them showing trend characteristics, seasonal variations and/or non-stationary behavior. We calculated error measures to evaluate the performance of MVA. The results of statistical tests and error measures revealed that MVA has a good performance compared to the accuracy obtained by the benchmarks considered in this work. In all cases, MVA surpassed other forecasting methods in Literature, which confirms that this work will contribute to the field of time series forecasting not only in the theoretical aspect, but also in practice.},
author = {Moreira, Filipe Rodrigues De Souza and Verri, Filipe Alves Neto and Yoneyama, Takashi},
doi = {10.1109/ACCESS.2022.3143106},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moreira, Verri, Yoneyama - 2022 - Maximum Visibility A Novel Approach for Time Series Forecasting Based on Complex Network Theory.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Autocorrelation,Bars,Complex networks,Forecasting,Mathematical models,Predictive models,Time series analysis},
pages = {8960--8973},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Maximum Visibility: A Novel Approach for Time Series Forecasting Based on Complex Network Theory}},
volume = {10},
year = {2022}
}
@article{Kocisky2008,
abstract = {Traffic profile, mainly its self-similarity properties, can have crucial impact on the network performance. In this regard, we evaluate traffic profile of Ethernet traffic. We have performed a measurement of the traffic on Ethernet network. Captured data has been analyzed from the protocol point of view, with the stress on the selfsimilarity, LRD and SRD properties. To evaluate these characteristics, properties of wavelet transform (DWT) are deployed and, based on a parameter, scaling property of traffic is estimated. We show that self-similarity is present in analyzed data and that it depends on analyzed time scale and on analyzed protocol.},
annote = {2, 12},
author = {Kocisk{\'{y}}, Michal and Lasz, Jozef and Kotuliak, Ivan},
doi = {10.2498/CIT.1000878},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocisk{\'{y}}, Lasz, Kotuliak - 2008 - Analysis of Ethernet traffic statistical properties.pdf:pdf},
issn = {18463908},
journal = {J. Comput. Inf. Technol.},
keywords = {Hurst parameter,LRD,SRD,Self-similarity,Traffic profile,Wavelet transform},
number = {1},
pages = {15--21},
publisher = {University of Zagreb},
title = {{Analysis of Ethernet traffic statistical properties}},
volume = {16},
year = {2008}
}
@inproceedings{Manjunath2021,
abstract = {The plethora of Internet of Things (IoT) devices leads to explosive network traffic. The network traffic classification (NTC) is an essential tool to explore behaviours of network flows, and NTC is required for Internet service providers (ISPs) to manage the performance of the IoT network. We propose a novel network data representation, treating the traffic data as a series of images. Thus, the network data is realized as a video stream to employ time-distributed (TD) feature learning. The intra-temporal information within the network statistical data is learned using convolutional neural networks (CNN) and long short-term memory (LSTM), and the inter pseudo-temporal feature among the flows is learned by TD multi-layer perceptron (MLP). We conduct experiments using a large data-set with more number of classes. The experimental result shows that the TD feature learning elevates the network classification performance by 10{\%}.},
archivePrefix = {arXiv},
arxivId = {2109.14696},
author = {Manjunath, Yoga Suhas Kuruba and Zhao, Sihao and Zhang, Xiao-Ping},
booktitle = {2021 IEEE 7th World Forum Internet Things},
doi = {10.1109/WF-IoT51360.2021.9595307},
eprint = {2109.14696},
file = {:home/jeff/Downloads/2109.14696v1.pdf:pdf},
isbn = {978-1-6654-4431-6},
keywords = {Internet of Things (IoT),convolutional neural network (CNN),deep learning,long short-term memory (LSTM),multilayer perceptron (MLP),network traffic classification (NTC),time-distributed (TD) feature learning},
month = {jun},
pages = {674--679},
publisher = {IEEE},
title = {{Time-Distributed Feature Learning in Network Traffic Classification for Internet of Things}},
url = {https://ieeexplore.ieee.org/document/9595307/},
year = {2021}
}
@article{Virtanen2020,
abstract = {SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.},
archivePrefix = {arXiv},
arxivId = {1907.10121},
author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, St{\'{e}}fan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R.J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^{o}}nio H. and Pedregosa, Fabian and van Mulbregt, Paul and Vijaykumar, Aditya and Bardelli, Alessandro Pietro and Rothberg, Alex and Hilboll, Andreas and Kloeckner, Andreas and Scopatz, Anthony and Lee, Antony and Rokem, Ariel and Woods, C. Nathan and Fulton, Chad and Masson, Charles and H{\"{a}}ggstr{\"{o}}m, Christian and Fitzgerald, Clark and Nicholson, David A. and Hagen, David R. and Pasechnik, Dmitrii V. and Olivetti, Emanuele and Martin, Eric and Wieser, Eric and Silva, Fabrice and Lenders, Felix and Wilhelm, Florian and Young, G. and Price, Gavin A. and Ingold, Gert Ludwig and Allen, Gregory E. and Lee, Gregory R. and Audren, Herv{\'{e}} and Probst, Irvin and Dietrich, J{\"{o}}rg P. and Silterra, Jacob and Webber, James T. and Slavi{\v{c}}, Janko and Nothman, Joel and Buchner, Johannes and Kulick, Johannes and Sch{\"{o}}nberger, Johannes L. and {de Miranda Cardoso}, Jos{\'{e}} Vin{\'{i}}cius and Reimer, Joscha and Harrington, Joseph and Rodr{\'{i}}guez, Juan Luis Cano and Nunez-Iglesias, Juan and Kuczynski, Justin and Tritz, Kevin and Thoma, Martin and Newville, Matthew and K{\"{u}}mmerer, Matthias and Bolingbroke, Maximilian and Tartre, Michael and Pak, Mikhail and Smith, Nathaniel J. and Nowaczyk, Nikolai and Shebanov, Nikolay and Pavlyk, Oleksandr and Brodtkorb, Per A. and Lee, Perry and McGibbon, Robert T. and Feldbauer, Roman and Lewis, Sam and Tygier, Sam and Sievert, Scott and Vigna, Sebastiano and Peterson, Stefan and More, Surhud and Pudlik, Tadeusz and Oshima, Takuya and Pingel, Thomas J. and Robitaille, Thomas P. and Spura, Thomas and Jones, Thouis R. and Cera, Tim and Leslie, Tim and Zito, Tiziano and Krauss, Tom and Upadhyay, Utkarsh and Halchenko, Yaroslav O. and V{\'{a}}zquez-Baeza, Yoshiki},
doi = {10.1038/S41592-019-0686-2},
eprint = {1907.10121},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Virtanen et al. - 2020 - SciPy 1.0 fundamental algorithms for scientific computing in Python.pdf:pdf},
issn = {15487105},
journal = {Nat. Methods},
month = {mar},
number = {3},
pages = {261--272},
pmid = {32015543},
publisher = {Nature Research},
title = {{SciPy 1.0: fundamental algorithms for scientific computing in Python}},
volume = {17},
year = {2020}
}
@article{Lines2018,
abstract = {A recent experimental evaluation assessed 19 time series classification (TSC) algorithms and found that one was significantly more accurate than all others: the Flat Collective of Transformation-based Ensembles (Flat- COTE). Flat-COTE is an ensemble that combines 35 classifiers over four data representations. However, while comprehensive, the evaluation did not consider deep learning approaches. Convolutional neural networks (CNN) have seen a surge in popularity and are now state of the art in many fields and raises the question of whether CNNs could be equally transformative for TSC. We implement a benchmark CNN for TSC using a common structure and use results from a TSC-specific CNN from the literature. We compare both to Flat-COTE and find that the collective is significantly more accurate than both CNNs. These results are impressive, but Flat-COTE is not without deficiencies.We significantly improve the collective by proposing a new hierarchical structure with probabilistic voting, defining and including two novel ensemble classifiers built in existing feature spaces, and adding further modules to represent two additional transformation domains. The resulting classifier, the Hierarchical Vote Collective of Transformation-based Ensembles (HIVE-COTE), encapsulates classifiers built on five data representations. We demonstrate that HIVE-COTE is significantly more accurate than Flat-COTE (and all other TSC algorithms that we are aware of) over 100 resamples of 85 TSC problems and is the new state of the art for TSC. Further analysis is included through the introduction and evaluation of 3 new case studies and extensive experimentation on 1,000 simulated datasets of 5 different types. 2018 Copyright is held by the owner/author(s).},
author = {Lines, Jason and Taylor, Sarah and Bagnall, Anthony},
doi = {10.1145/3182382},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lines, Taylor, Bagnall - 2018 - Time series classification with HIVE-COTE The hierarchical vote collective of transformation-based ensem.pdf:pdf},
issn = {1556472X},
journal = {ACM Trans. Knowl. Discov. Data},
keywords = {Deep learning,Heterogeneous ensembles,Meta ensembles,Time series classification},
month = {jul},
number = {5},
publisher = {Association for Computing Machinery},
title = {{Time series classification with HIVE-COTE: The hierarchical vote collective of transformation-based ensembles}},
volume = {12},
year = {2018}
}
@article{Dickey1997,
abstract = {The subject of time series is of considerable interest, especially among researchers in econometrics, engineering, and the natural sciences. As part of the prestigious Wiley Series in Probability and Statistics, this book provides a lucid introduction to the field and, in this new Second Edition, covers the important advances of recent years, including nonstationary models, nonlinear estimation, multivariate models, state space representations, and empirical model identification. New sections have also been added on the Wold decomposition, partial autocorrelation, long memory processes, and the Kalman filter.Major topics include: * Moving average and autoregressive processes * Introduction to Fourier analysis * Spectral theory and filtering * Large sample theory * Estimation of the mean and autocorrelations * Estimation of the spectrum * Parameter estimation * Regression, trend, and seasonality * Unit root and explosive time seriesTo accommodate a wide variety of readers, review material, especially on elementary results in Fourier analysis, large sample statistics, and difference equations, has been included.},
author = {Dickey, David A. and Fuller, Wayne A.},
doi = {10.2307/1270782},
issn = {00401706},
journal = {Technometrics},
month = {feb},
number = {1},
pages = {103},
publisher = {JSTOR},
title = {{Introduction to Statistical Time Series}},
volume = {39},
year = {1997}
}
@article{Zaliapin2003,
annote = {Samorodnitsky and Taqqu,
Uchaikin and Zolotarev, 1999},
author = {Zaliapin, Ilya and Kagan, Yan Y and Schoenberg, Federic P and Org, Escholarship},
file = {:home/jeff/Downloads/qt8940b4k8.pdf:pdf},
title = {{Approximating the Distribution of Pareto Sums}},
url = {https://escholarship.org/uc/item/8940b4k8},
year = {2003}
}
@article{Kattepur2021,
author = {Kattepur, Ajay and David, Sushanth and Mohalik, Swarup Kumar},
doi = {10.23919/ICN.2021.0016},
file = {:home/jeff/Downloads/Model-based{\_}reinforcement{\_}learning{\_}for{\_}router{\_}port{\_}queue{\_}configurations.pdf:pdf},
keywords = {model-based reinforcement learning,network slicing,rl,router port queues},
number = {3},
title = {{Model-based reinforcement learning for router port queue configurations}},
volume = {2},
year = {2021}
}
@article{Zhang2020,
abstract = {Covert channel is an important way to transmit covert message and implement covert communication through the network. However, the existing research on covert channel cannot meet the security requirements of covert communication in the complex mobile networks. There are problems such as low transmission capacity, insufficient adaptability to network complexity, and difficulty in countering the detection of covert channels by adversaries. In this paper, we preprocess video traffics over mobile network, and extract traffic features to build a target model. We analysis traffic data by machine learning method to improve the undetectability of the covert channel. Based on the characteristics of real-time interactive communication, gray code and interval block are employed to improve the robustness of covert communication in the complex network environment. A cover channel over VoLTE video traffic, which is based on video packet reordering supported by machine learning algorithms, is proposed to realize the awareness and confrontation of detection attacks on the network side. The covert channel is built over mobile network to ensure end-to-end reliable covert communication under complex network conditions.},
author = {Zhang, Xiaosong and Pang, Ling and Guo, Linhong and Li, Yuanzhang},
doi = {10.1007/978-3-030-62223-7_28},
isbn = {9783030622220},
issn = {16113349},
journal = {Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)},
keywords = {Covert channel,Machine learning,Mobile networks,Undetectability},
pages = {331--339},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Building Undetectable Covert Channels Over Mobile Networks with Machine Learning}},
volume = {12486 LNCS},
year = {2020}
}
@article{Yperman2020,
author = {Yperman, Jan and Becker, Thijs and Valkenborg, Dirk and Popescu, Veronica and Hellings, Niels and Van, Bart and Peeters, Liesbet M},
file = {:home/jeff/Downloads/Yperman2020{\_}Article{\_}MachineLearningAnalysisOfMotor.pdf:pdf},
keywords = {Evoked potentials,Multiple sclerosis,Machine learn,be,belgium,correspondence,data science institute,diepenbeek,disease prognosis,evoked potentials,feature extraction,hasselt university,i-biostat,jan{\_}yperman,machine learning,multiple sclerosis,theoretical physics,uhasselt},
pages = {1--15},
publisher = {BMC Neurology},
title = {{Machine learning analysis of motor evoked potential time series to predict disability progression in multiple sclerosis}},
year = {2020}
}
@article{Huang2017,
abstract = {Most software profiling tools quantify average performance and rely on a program's control flow graph to organize and report results. However, in interactive server applications, performance predictability is often an equally important measure. Moreover, the end user is often concerned with the performance of a semantically defined interval of execution, such as a request or transaction, which may not directly map to any single function in the call graph, especially in high-performance applications that use asynchrony or event-based programming. It is difficult to distinguish functionality that lies on the critical path of a semantic interval from other activity (e.g., periodic logging or side operations) that may nevertheless appear prominent in a conventional profile. Existing profilers lack the ability to (i) aggregate results for a semantic interval and (ii) attribute its performance variance to individual functions. We propose a profiler called VProfiler that, given the source code of a software system and programmer annotations indicating the start and end of semantic intervals of interest, is able to identify the dominant sources of latency variance in a semantic context. Using a novel abstraction, called a variance tree, VProfiler analyzes the thread interleaving and deconstructs overall latency variance into variances and covariances of the execution time of individual functions. It then aggregates latency variance along a backwards path of dependence relationships among threads from the end of an interval to its start. We evaluate VProfiler's effectiveness on three popular open-source projects (MySQL, Postgres, and ApacheWeb Server). By identifying a few culprit functions in these complex code bases, VProfiler allows us to eliminate 27{\%}-82{\%} of the overall latency variance of these systems with a modest programming effort.},
author = {Huang, Jiamin and Mozafari, Barzan and Wenisch, Thomas F.},
doi = {10.1145/3064176.3064179},
file = {:home/jeff/Downloads/eurosys{\_}2017.pdf:pdf},
isbn = {9781450349383},
journal = {Proc. 12th Eur. Conf. Comput. Syst. EuroSys 2017},
keywords = {Performance,Predictability,Semantic profiling,Tail latencies,Variance},
month = {apr},
pages = {64--79},
publisher = {Association for Computing Machinery, Inc},
title = {{Statistical analysis of latency through semantic profiling}},
year = {2017}
}
@inproceedings{Zdravevski2015,
author = {Zdravevski, Eftim and Lameski, Petre and Mingov, Riste and Kulakov, Andrea and Gjorgjevikj, Dejan},
doi = {10.15439/2015F420},
file = {:home/jeff/Downloads/420.pdf:pdf},
isbn = {9788360810668},
keywords = {be performed when,classification,dimensionality reduction and data,feature engineering,feature reduction,of the most important,representation is one,tasks that need to,temporal data mining,time series},
month = {oct},
pages = {381--388},
title = {{Robust histogram-based feature engineering of time series data}},
url = {https://fedcsis.org/proceedings/2015/drp/420.html},
volume = {5},
year = {2015}
}
@article{Yuan2020a,
abstract = {Causal inference from observation data is a core problem in many scientific fields. Here we present a general supervised deep learning framework that infers causal interactions by transforming the input vectors to an image-like representation for every pair of inputs. Given a training dataset we first construct a normalized empirical probability density distribution (NEPDF) matrix. We then train a convolutional neural network (CNN) on NEPDFs for causality predictions. We tested the method on several different simulated and real world data and compared it to prior methods for causal inference. As we show, the method is general, can efficiently handle very large datasets and improves upon prior methods.},
archivePrefix = {arXiv},
arxivId = {2011.12508},
author = {Yuan, Ye and Ding, Xueying and Bar-Joseph, Ziv},
eprint = {2011.12508},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan, Ding, Bar-Joseph - 2020 - Causal inference using deep neural networks(2).pdf:pdf},
isbn = {2011.12508v1},
month = {nov},
title = {{Causal inference using deep neural networks}},
url = {https://arxiv.org/abs/2011.12508v1 http://arxiv.org/abs/2011.12508},
year = {2020}
}
@article{Fawaz2019,
abstract = {Transfer learning for deep neural networks is the process of first training a base network on a source dataset, and then transferring the learned features (the network's weights) to a second network to be trained on a target dataset. This idea has been shown to improve deep neural network's generalization capabilities in many computer vision tasks such as image recognition and object localization. Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community. However, unlike for image recognition problems, transfer learning techniques have not yet been investigated thoroughly for the TSC task. This is surprising as the accuracy of deep learning models for TSC could potentially be improved if the model is fine-tuned from a pre-trained neural network instead of training it from scratch. In this paper, we fill this gap by investigating how to transfer deep CNNs for the TSC task. To evaluate the potential of transfer learning, we performed extensive experiments using the UCR archive which is the largest publicly available TSC benchmark containing 85 datasets. For each dataset in the archive, we pre-trained a model and then fine-tuned it on the other datasets resulting in 7140 different deep neural networks. These experiments revealed that transfer learning can improve or degrade the models predictions depending on the dataset used for transfer. Therefore, in an effort to predict the best source dataset for a given target dataset, we propose a new method relying on Dynamic Time Warping to measure inter-datasets similarities. We describe how our method can guide the transfer to choose the best source dataset leading to an improvement in accuracy on 71 out of 85 datasets.},
archivePrefix = {arXiv},
arxivId = {1811.01533},
author = {Fawaz, Hassan Ismail and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre Alain},
doi = {10.1109/BIGDATA.2018.8621990},
eprint = {1811.01533},
isbn = {9781538650356},
journal = {Proc. - 2018 IEEE Int. Conf. Big Data, Big Data 2018},
keywords = {Dynamic Time Warping,Transfer learning,deep learning,time series classification},
month = {jan},
pages = {1367--1376},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Transfer learning for time series classification}},
year = {2019}
}
@article{Feng2022,
abstract = {In multivariate time series modeling, it is necessary to capture short-term mutation and long-term dependence information simultaneously. However, mechanism which can capture short-term change is difficult to be used to grasp long-term dependence information, and vice versa. In order to capture both short-term mutation and long-term dependence information in the same model, this paper proposed a dual-staged attention mechanism based on conversion-gated Long Short Term Memory network(DA-CG-LSTM). Hyperbolic tangent function is introduced into the input-gate and the forget-gate of Long Short Term Memory network(LSTM), which improves the ability of the network to extract the short-term mutation information. Further, dual-staged attention mechanism is added in the network, which includes input attention and temporal attention. Input attention adaptively extracts the feature relations of exogenous sequences, and temporal attention selects the relevant hidden layer states across all the time steps. Experiments on air quality and traffic flow time series data show that the proposed network has lower average absolute error, average absolute percentage error and root mean square error by more than 50{\%} compared with Dual-staged Attention Recurrent Neural Network(DA-RNN) and Transformation-gated LSTM(TG-LSTM).},
author = {Feng, Shufang and Feng, Yong},
doi = {10.1109/ACCESS.2021.3136712},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feng, Feng - 2022 - A Dual-Staged Attention Based Conversion-Gated Long Short Term Memory for Multivariable Time Series Prediction.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Conversion-gated,dual-staged attention mechanism,long short-term memory network,time series prediction},
pages = {368--379},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A Dual-Staged Attention Based Conversion-Gated Long Short Term Memory for Multivariable Time Series Prediction}},
volume = {10},
year = {2022}
}
@article{Aggarwal2004,
abstract = {Current models of the classification problem do not effectively handle bursts of particular classes coming in at different times. In fact, the current model of the classification problem simply concentrates on methods for one-pass classification modeling of very large data sets. Our model for data stream classification views the data stream classification problem from the point of view of a dynamic approach in which simultaneous training and testing streams are used for dynamic classification of data sets. This model reflects real life situations effectively, since it is desirable to classify test streams in real time over an evolving training and test stream. The aim here is to create a classification system in which the training model can adapt quickly to the changes of the underlying data stream. In order to achieve this goal, we propose an on-demand classification process which can dynamically select the appropriate window of past training data to build the classifier. The empirical results indicate that the system maintains a high classification accuracy in an evolving data stream, while providing an efficient solution to the classification task.},
author = {Aggarwal, Charu C. and Han, Jiawei and Wang, Jianyong and Yu, Philip S.},
doi = {10.1145/1014052.1014110},
file = {:home/jeff/Downloads/kdd04{\_}streamclassif.pdf:pdf},
isbn = {1581138881},
journal = {KDD-2004 - Proc. Tenth ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.},
keywords = {Classification,Data streams},
pages = {503--508},
title = {{On demand classification of data streams}},
year = {2004}
}
@article{Crotti2007,
abstract = {The classification of IP ows according to the application that generated them is at the basis of any modern network management platform. However, classical techniques such as the ones based on the analysis of transport layer or application layer information are rapidly becoming ineffective. In this paper we present a ow classification mechanism based on three simple properties of the captured IP packets: their size, inter-arrival time and arrival order. Even though these quantities have already been used in the past to define classification techniques, our contribution is based on new structures called protocol fingerprints, which express such quantities in a compact and efficient way, and on a simple classification algorithm based on normalized thresholds. Although at a very early stage of development, the proposed technique is showing promising preliminary results from the classification of a reduced set of protocols.},
author = {Crotti, Manuel and Dusi, Maurizio and Gringoli, Francesco and Salgarelli, Luca},
doi = {10.1145/1198255.1198257},
file = {:home/jeff/Downloads/p7-v37n1b-crotti.pdf:pdf},
issn = {0146-4833},
journal = {ACM SIGCOMM Comput. Commun. Rev.},
keywords = {traffic classification,transport layer},
month = {jan},
number = {1},
pages = {5--16},
title = {{Traffic classification through simple statistical fingerprinting}},
url = {https://dl.acm.org/doi/10.1145/1198255.1198257},
volume = {37},
year = {2007}
}
@article{Celik2006,
abstract = {A novel reversible data hiding algorithm, which can recover the original image without any distortion from the marked image after the hidden data have been extracted, is presented in this paper. This algorithm utilizes the zero or the minimum points of the histogram of an image and slightly modifies the pixel grayscale values to embed data into the image. It can embed more data than many of the existing reversible data hiding algorithms. It is proved analytically and shown experimentally that the peak signal-to-noise ratio (PSNR) of the marked image generated by this method versus the original image is guaranteed to be above 48 dB. This lower bound of PSNR is much higher than that of all reversible data hiding techniques reported in the literature. The computational complexity of our proposed technique is low and the execution time is short. The algorithm has been successfully applied to a wide range of images, including commonly used images, medical images, texture images, aerial images and all of the 1096 images in CorelDraw database. Experimental results and performance comparison with other reversible data hiding schemes are presented to demonstrate the validity of the proposed algorithm. {\textcopyright} 2006 IEEE.},
author = {{Zhicheng Ni} and {Yun-Qing Shi} and Ansari, N. and {Wei Su}},
doi = {10.1109/TCSVT.2006.869964},
file = {:home/jeff/Downloads/Reversible{\_}data{\_}hiding20160726-6263-d7pg1p-with-cover-page-v2.pdf:pdf},
issn = {1051-8215},
journal = {IEEE Trans. Circuits Syst. Video Technol.},
keywords = {Histogram modification,Reversible (lossless) data hiding,Watermarking},
month = {mar},
number = {3},
pages = {354--362},
title = {{Reversible data hiding}},
url = {http://ieeexplore.ieee.org/document/1608163/},
volume = {16},
year = {2006}
}
@article{Graja2004,
abstract = {A novel methodology is proposed for the analysis of the IP packet delay performance of SR-ARQ mechanisms in a generalized wireless system. A simulation model of the system including a novel channel model is described and results are obtained for a range of IP packet size. To demonstrated the efficacy of the methodology, the test scenario is tailored to the transmission of small packets containing real-time data carried over an EGPRS system. The results show that the use of a mean value for IP packet delay estimation is of limited use when small packets are considered.},
author = {Graja, Hubert and Perry, Philip and Murphy, John},
doi = {10.1109/PIMRC.2004.1368325},
journal = {IEEE Int. Symp. Pers. Indoor Mob. Radio Commun. PIMRC},
keywords = {ARQ,IP packet delay,Mobile multimedia,Wireless QoS},
pages = {1881--1885},
title = {{A statistical analysis of IP packet delay and jitter in cellular networks}},
volume = {3},
year = {2004}
}
@article{Cavusobglu2020,
abstract = {A covert channel is a communication method that misuses legitimate resources to bypass intrusion detection systems. They can be used to do illegal work like leaking classified (or sensitive) data or sending commands to malware bots. Network timing channels are a type of these channels that use inter-arrival times between network packets to encode the data to be sent. In this study, we worked with two types of network covert channels: Fixed Interval and Jitterbug. We were able to distinguish these channels from legitimate ones by using decision trees that use four statistical features (mean, variance, skewness, and kurtosis).},
author = {Cavusobglu, Imge Gamze and Alemdar, Hande and Onur, Ertan},
doi = {10.1109/SIU49456.2020.9302098},
isbn = {9781728172064},
journal = {2020 28th Signal Process. Commun. Appl. Conf. SIU 2020 - Proc.},
keywords = {Covert Channel,Covert Channel Detection,Decision Tree,Machine Learning},
month = {oct},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Covert Channel Detection Using Machine Learning}},
year = {2020}
}
@article{Christodoulou2019,
abstract = {Objectives: The objective of this study was to compare performance of logistic regression (LR) with machine learning (ML) for clinical prediction modeling in the literature. Study Design and Setting: We conducted a Medline literature search (1/2016 to 8/2017) and extracted comparisons between LR and ML models for binary outcomes. Results: We included 71 of 927 studies. The median sample size was 1,250 (range 72–3,994,872), with 19 predictors considered (range 5–563) and eight events per predictor (range 0.3–6,697). The most common ML methods were classification trees, random forests, artificial neural networks, and support vector machines. In 48 (68{\%}) studies, we observed potential bias in the validation procedures. Sixty-four (90{\%}) studies used the area under the receiver operating characteristic curve (AUC) to assess discrimination. Calibration was not addressed in 56 (79{\%}) studies. We identified 282 comparisons between an LR and ML model (AUC range, 0.52–0.99). For 145 comparisons at low risk of bias, the difference in logit(AUC) between LR and ML was 0.00 (95{\%} confidence interval, −0.18 to 0.18). For 137 comparisons at high risk of bias, logit(AUC) was 0.34 (0.20–0.47) higher for ML. Conclusion: We found no evidence of superior performance of ML over LR. Improvements in methodology and reporting are needed for studies that compare modeling algorithms.},
author = {Christodoulou, Evangelia and Ma, Jie and Collins, Gary S. and Steyerberg, Ewout W. and Verbakel, Jan Y. and {Van Calster}, Ben},
doi = {10.1016/j.jclinepi.2019.02.004},
issn = {08954356},
journal = {J. Clin. Epidemiol.},
keywords = {AUC,Calibration,Clinical prediction models,Logistic regression,Machine learning,Reporting},
month = {jun},
pages = {12--22},
title = {{A systematic review shows no performance benefit of machine learning over logistic regression for clinical prediction models}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435618310813},
volume = {110},
year = {2019}
}
@article{Omar2019,
abstract = {Most binary classifiers work by processing the input to produce a scalar response and comparing it to a threshold value. The various measures of classifier performance assume, explicitly or implicitly, probability distributions Ps and Pn of the response belonging to either class, probability distributions for the cost of each type of misclassification, and compute a performance score from the expected cost. In machine learning, classifier responses are obtained experimentally and performance scores are computed directly from them, without any assumptions on Ps and Pn. Here, we argue that the omitted step of estimating theoretical distributions for Ps and Pn can be useful. In a biometric security example, we fit beta distributions to the responses of two classifiers, one based on logistic regression and one on ANNs, and use them to establish a categorisation into a small number of classes with different extremal behaviours at the ends of the ROC curves.},
archivePrefix = {arXiv},
arxivId = {1909.09816},
author = {Omar, Luma and Ivrissimtzis, Ioannis},
doi = {10.1016/j.patrec.2019.10.004},
eprint = {1909.09816},
file = {:home/jeff/Downloads/1909.09816.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognit. Lett.},
keywords = {Beta distribution,Binary classification,Classifier analysis,Detection theory,ROC curve},
pages = {447--451},
title = {{Using theoretical ROC curves for analysing machine learning binary classifiers}},
volume = {128},
year = {2019}
}
@misc{Ziviani2004,
author = {Ziviani, Artur; and Fdida, Serge; and de; Rezende, Jos{\'{e}} F. and Duarte, Otto Carlos M. B.},
file = {:home/jeff/Downloads/ZFRD04a.ps.gz:gz},
keywords = {Ziviani2004},
title = {{Improving the Accuracy of Measurement-Based Geographic Location of Internet Hosts}},
year = {2004}
}
@article{Epishkina2019a,
abstract = {Currently, packet data networks are widespread. Their architectural features allow constructing covert channels that are able to transmit covert data under the conditions of using standard protection measures. However, encryption or packets length normalization, leave the possibility for an intruder to transfer covert data via timing covert channels (TCCs). In turn, inter-packet delay (IPD) normalization leads to reducing communication channel capacity. Detection is an alternative countermeasure. At the present time, detection methods based on machine learning are widely studied. The complexity of TCCs detection based on machine learning depends on the availability of traffic samples, and on the possibility of an intruder to change covert channels parameters. In the current work, we explore the cases of TCCs detection via.},
author = {Epishkina, Anna and Finoshin, Mikhail and Kogos, Konstantin and Yazykova, Aleksandra},
doi = {10.1109/EISIC49498.2019.9108873},
file = {:home/jeff/Downloads/Papers/Timing{\_}Covert{\_}Channels{\_}Detection{\_}Cases{\_}via{\_}Machine{\_}Learning(1).pdf:pdf},
isbn = {9781728167350},
journal = {Proc. 2019 Eur. Intell. Secur. Informatics Conf. EISIC 2019},
month = {nov},
pages = {139},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Timing covert channels detection cases via machine learning}},
year = {2019}
}
@book{TCSEC,
author = {{US Department of Defense}},
file = {:home/jeff/Downloads/dod85.pdf:pdf},
title = {{Trusted Computer System Evaluation Criteria}},
year = {1983}
}
@article{Crovella1997,
author = {Crovella, M.E. and Bestavros, Azer},
doi = {10.1109/90.650143},
file = {:home/jeff/Downloads/journal-version.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Trans. Netw.},
number = {6},
pages = {835--846},
title = {{Self-similarity in World Wide Web traffic: evidence and possible causes}},
url = {http://ieeexplore.ieee.org/document/650143/},
volume = {5},
year = {1997}
}
@article{Jordanova2019,
author = {Jordanova, Pavlina K and Petkova, Monika P},
file = {:home/jeff/Downloads/1.5013996.pdf:pdf},
isbn = {9780735416024},
number = {December 2017},
title = {{Measuring heavy-tailedness of distributions}},
volume = {060002},
year = {2019}
}
@article{Chu2019,
abstract = {The goal of this paper is to provide a unifying view of a wide range of problems of interest in machine learning by framing them as the minimization of functionals defined on the space of probability measures. In particular, we show that generative adversarial networks, variational inference, and actor-critic methods in reinforcement learning can all be seen through the lens of our framework. We then discuss a generic optimization algorithm for our formulation, called probability functional descent (PFD), and show how this algorithm recovers existing methods developed independently in the settings mentioned earlier.},
archivePrefix = {arXiv},
arxivId = {1901.10691},
author = {Chu, Casey and Blanchet, Jose and Glynn, Peter},
eprint = {1901.10691},
file = {:home/jeff/Downloads/1901.10691.pdf:pdf},
isbn = {9781510886988},
journal = {36th Int. Conf. Mach. Learn. ICML 2019},
pages = {2071--2087},
title = {{Probability functional descent: A unifying perspective on GANs, variational inference, and reinforcement learning}},
volume = {2019-June},
year = {2019}
}
@article{Keller2021,
abstract = {Covert channels enable stealthy communications over innocent appearing carriers. They are increasingly applied in the network context. However, little work is available that exploits cryptographic primitives in the networking context to establish such covert communications. We present a covert channel between two devices where one device authenticates itself with Lamport's one-time passwords based on a cryptographic hash function. Our channel enables plausible deniability jointly with reversibility and is applicable in different contexts, such as traditional TCP/IP networks, CPS/IoT communication, blockchain-driven systems and local inter-process communications that apply hash chains. We also present countermeasures to detect the presence of such a covert channel, which are non-trivial because hash values are random-looking binary strings, so that deviations are not likely to be detected. We report on experimental results with MD5 and SHA-3 hash functions for two covert channel variants running in a localhost setup. In particular, we evaluate the channels' time performance, conduct statistical tests using the NIST suite and run a test for matching hash values between legitimate and covert environments to determine our channels' stealthiness.},
author = {Keller, J{\"{o}}rg and Wendzel, Steffen},
doi = {10.3390/app11020731},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keller, Wendzel - 2021 - Reversible and Plausibly Deniable Covert Channels in One-Time Passwords Based on Hash Chains.pdf:pdf},
issn = {2076-3417},
journal = {Appl. Sci.},
keywords = {covert channel,cryptographic hash function,hash chain,plausible deniability,steganography},
month = {jan},
number = {2},
pages = {731},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Reversible and Plausibly Deniable Covert Channels in One-Time Passwords Based on Hash Chains}},
url = {https://www.mdpi.com/2076-3417/11/2/731/htm https://www.mdpi.com/2076-3417/11/2/731},
volume = {11},
year = {2021}
}
@article{Keller2021a,
author = {Keller, J{\"{o}}rg; and Wendzel, Steffen},
file = {:home/jeff/Downloads/applsci-11-00731-v2.pdf:pdf},
keywords = {cryptographic hash function,hash chain,plausible deniability,steganography},
title = {{applied sciences Reversible and Plausibly Deniable Covert Channels in One-Time Passwords Based on Hash Chains †}},
year = {2021}
}
@misc{RIPE,
title = {{Index of /datasets/atlas-daily-dumps}},
url = {https://data-store.ripe.net/datasets/atlas-daily-dumps/},
urldate = {2022-05-23}
}
@inproceedings{Wang2018,
author = {Wang, Wei and Zhu, Ming and Wang, Jinlin and Zeng, Xuewen and Yang, Zhongzhen},
booktitle = {2017 IEEE Int. Conf. Intell. Secur. Informatics},
doi = {10.1109/ISI.2017.8004872},
file = {:home/jeff/Downloads/End-to-endEncryptedTrafficClassificationwithOne-dimensionalConvolutionNeuralNetworks-EN-wangwei.pdf:pdf},
isbn = {978-1-5090-6727-5},
keywords = {dimensional convolutional neural networks,encrypted traffic classification,end-to-end,engineering research center,jinlin wang,national network new media,one-,xuewen zeng,zhongzhen yang},
month = {jul},
number = {July 2017},
pages = {43--48},
publisher = {IEEE},
title = {{End-to-end encrypted traffic classification with one-dimensional convolution neural networks}},
url = {http://ieeexplore.ieee.org/document/8004872/},
year = {2017}
}
@article{Balaji2015a,
abstract = {Automatic classification cardiac views is the first step to automate wall motion analysis, computer aided disease diagnosis, measurement computation etc. In this paper a fully automatic classification of cardiac view in echocardiogram is proposed. The system is built based on a machine learning approach which characterizes two features 1) Histogram features and 2) Statistical features. In this system four standard views parasternal short axis (PSAX), parasternal long axis (PLAX), apical two chamber (A2C) and apical four chamber (A4C) views are classified. Experiments over 200 echocardiogram images show that the proposed method with an accuracy of 87.5{\%} can be effectively used in cardiac view classification.},
author = {Balaji, G. N. and Subashini, T. S. and Chidambaram, N.},
doi = {10.1016/j.procs.2015.02.084},
file = {:home/jeff/Downloads/1-s2.0-S1877050915001489-main.pdf:pdf},
issn = {18770509},
journal = {Procedia Comput. Sci.},
keywords = {Apical two chamber (A2C) and apical four chamber (,Parasternal long axis (PLAX),Parasternal short axis (PSAX)},
number = {Icict 2014},
pages = {1569--1576},
publisher = {Elsevier Masson SAS},
title = {{Automatic classification of cardiac views in echocardiogram using histogram and statistical features}},
url = {http://dx.doi.org/10.1016/j.procs.2015.02.084},
volume = {46},
year = {2015}
}
@article{Caballero2007,
author = {Caballero, F J Vaquero and Ives, D J},
file = {:home/jeff/Downloads/bare{\_}jrnl (1).pdf:pdf},
number = {1},
pages = {1--10},
title = {{Neural Network based Linear and Nonlinear Noise Estimation}},
volume = {6},
year = {2007}
}
@article{Webb2012,
abstract = {Averaged n-Dependence Estimators (AnDE) is an approach to probabilistic classification learning that learns by extrapolation from marginal to full-multivariate probability distributions. It utilizes a single parameter that transforms the approach between a lowvariance high-bias learner (Naive Bayes) and a high-variance low-bias learner with Bayes optimal asymptotic error. It extends the underlying strategy of Averaged One-Dependence Estimators (AODE), which relaxes the Naive Bayes independence assumption while retaining many of Naive Bayes' desirable computational and theoretical properties. AnDE further relaxes the independence assumption by generalizing AODE to higher-levels of dependence. Extensive experimental evaluation shows that the bias-variance trade-off for Averaged 2-Dependence Estimators results in strong predictive accuracy over a wide range of data sets. It has training time linear with respect to the number of examples, learns in a single pass through the training data, supports incremental learning, handles directly missing values, and is robust in the face of noise. Beyond the practical utility of its lower-dimensional variants, AnDE is of interest in that it demonstrates that it is possible to create low-bias high-variance generative learners and suggests strategies for developing even more powerful classifiers. {\textcopyright} The Author(s) 2011.},
author = {Webb, Geoffrey I. and Boughton, Janice R. and Zheng, Fei and Ting, Kai Ming and Salem, Houssam},
doi = {10.1007/s10994-011-5263-6},
file = {:home/jeff/Downloads/Webb2012{\_}Article{\_}LearningByExtrapolationFromMar.pdf:pdf},
issn = {08856125},
journal = {Mach. Learn.},
keywords = {Averaged one-dependence estimators,Bayesian learning,Classification learning,Ensemble learning,Feating,Learning without model selection,Naive Bayes,Probabilistic learning,Semi-naive Bayesian learning},
number = {2},
pages = {233--272},
title = {{Learning by extrapolation from marginal to full-multivariate probability distributions: Decreasingly naive Bayesian classification}},
volume = {86},
year = {2012}
}
@inproceedings{Epishkina2019,
abstract = {Currently, packet data networks are widespread. Their architectural features allow constructing covert channels that are able to transmit covert data under the conditions of using standard protection measures. However, encryption or packets length normalization, leave the possibility for an intruder to transfer covert data via timing covert channels (TCCs). In turn, inter-packet delay (IPD) normalization leads to reducing communication channel capacity. Detection is an alternative countermeasure. At the present time, detection methods based on machine learning are widely studied. The complexity of TCCs detection based on machine learning depends on the availability of traffic samples, and on the possibility of an intruder to change covert channels parameters. In the current work, we explore the cases of TCCs detection via.},
author = {Epishkina, Anna and Finoshin, Mikhail and Kogos, Konstantin and Yazykova, Aleksandra},
booktitle = {2019 Eur. Intell. Secur. Informatics Conf.},
doi = {10.1109/EISIC49498.2019.9108873},
file = {:home/jeff/Downloads/Papers/Covert{\_}Channel{\_}Detection{\_}Using{\_}Machine{\_}Learning(1).pdf:pdf},
isbn = {978-1-7281-6735-0},
keywords = {Active warden,Data leakage protection,Information hiding,Network steganography,covert channel,covert channel detection,daha sonra,decision tree,her bir sembol{\"{u}} yollarken,hine learning,kar,mac-,mesajı g{\"{o}}nderen taraf,zaman farkı tanımlanır},
month = {nov},
pages = {139--139},
publisher = {IEEE},
title = {{Timing Covert Channels Detection Cases via Machine Learning}},
url = {https://ieeexplore.ieee.org/document/9108873/},
volume = {10},
year = {2019}
}
@article{Cottrel2015,
author = {Cottrell, R Les},
file = {:home/jeff/Downloads/slac-pub-16463.pdf:pdf},
title = {{Adaptive Geolocation of Internet Hosts}},
year = {2015}
}
@article{YiZhengQiLiuEnhongChenYongGe2014,
abstract = {Time series (particularly multivariate) classification has drawn a lot of attention in the literature because of its broad applica- tions for different domains, such as health informatics and bioinformatics. Thus, many algorithms have been developed for this task. Among them, nearest neighbor classification (particularly 1-NN) combined with Dy- namic Time Warping (DTW) achieves the state of the art performance. However, when data set grows larger, the time consumption of 1-NN with DTW grows linearly. Compared to 1-NN with DTW, the tradi- tional feature-based classification methods are usually more efficient but less effective since their performance is usually dependent on the qual- ity of hand-crafted features. To that end, in this paper, we explore the feature learning techniques to improve the performance of traditional feature-based approaches. Specifically, we propose a novel deep learn- ing framework for multivariate time series classification. We conduct two groups of experiments on real-world data sets from different application domains. The final results show that our model is not only more effi- cient than the state of the art but also competitive in accuracy. It also demonstrates that feature learning is worth to investigate for time series classification.},
annote = {This paper is really helpfull, both for suggesting easy and hard machine learning approaches.

References 4-7; 11; 14-15 are worth checking out.},
author = {{Yi Zheng , Qi Liu , Enhong Chen , Yong Ge}, and J. Leon Zhao},
file = {:home/jeff/Downloads/WAIM2014.pdf:pdf},
keywords = {Neural Networks},
mendeley-tags = {Neural Networks},
title = {{Time Series Classification Using Multi-Channels Deep Convolutional Neural Networks}},
year = {2014}
}
@article{Pedregosa2011,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.org.},
archivePrefix = {arXiv},
arxivId = {1201.0490},
author = {Pedregosa, Fabian and Varoquaux, Ga{\"{e}}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and M{\"{u}}ller, Andreas and Nothman, Joel and Louppe, Gilles and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'{E}}douard},
eprint = {1201.0490},
isbn = {1532-4435},
issn = {15324435},
journal = {J. Mach. Learn. Res.},
keywords = {Python,model selection,supervised learning,unsupervised learning},
month = {jan},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://arxiv.org/abs/1201.0490},
volume = {12},
year = {2012}
}
@article{Rodriguez2006,
abstract = {We propose a method for generating classifier ensembles based on feature extraction. To create the training data for a base classifier, the feature set is randomly split into K subsets (K is a parameter of the algorithm) and Principal Component Analysis (PCA) is applied to each subset. All principal components are retained in order to preserve the variability information in the data. Thus, K axis rotations take place to form the new features for a base classifier. The idea of the rotation approach is to encourage simultaneously individual accuracy and diversity within the ensemble. Diversity is promoted through the feature extraction for each base classifier. Decision trees were chosen here because they are sensitive to rotation of the feature axes, hence the name "forest." Accuracy is sought by keeping all principal components and also using the whole data set to train each base classifier. Using WEKA, we examined the Rotation Forest ensemble on a random selection of 33 benchmark data sets from the UCI repository and compared it with Bagging, AdaBoost, and Random Forest. The results were favorable to Rotation Forest and prompted an investigation into diversity-accuracy landscape of the ensemble models. Diversity-error diagrams revealed that Rotation Forest ensembles construct individual classifiers which are more accurate than these in AdaBoost and Random Forest, and more diverse than these in Bagging, sometimes more accurate as well. {\textcopyright} 2006 IEEE.},
author = {Rodr{\'{i}}guez, Juan J. and Kuncheva, Ludmila I. and Alonso, Carlos J.},
doi = {10.1109/TPAMI.2006.211},
issn = {01628828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
keywords = {AdaBoost,Bagging,Classifier ensembles,Feature extraction,Kappa-error diagrams,PCA,Random forest},
number = {10},
pages = {1619--1630},
pmid = {16986543},
title = {{Rotation forest: A New classifier ensemble method}},
volume = {28},
year = {2006}
}
@article{Huy2013,
author = {Huy, Quang and Universit{\'{e}}, Nguyen and Saf, Laboratoire and Robert, Christian and Lyon, Universit{\'{e}} and Saf, Laboratoire and Nguyen, Quang Huy and Robert, Christian Y},
file = {:home/jeff/Downloads/10.1.1.1066.2990.pdf:pdf},
title = {{Series expansions for sums of independent Pareto random variables Series expansions for sums of independent Pareto random variables}},
volume = {16},
year = {2013}
}
@article{Karci2019,
author = {Karci, Ali},
file = {:home/jeff/Desktop/SynologyDrive/projekte/Bachelor/papers/timing covert channels/Detection{\_}of{\_}Covert{\_}Timing{\_}Channels{\_}with{\_}Machine{\_}Learning{\_}Methods{\_}Using{\_}Different{\_}Window{\_}Sizes(1).pdf:pdf},
title = {{Gizli Zamanlama Kanalının Farklı Pencere Boyutları Kullanılarak Makine {\"{O}}ğrenmesi Y{\"{o}}ntemleriyle Algılanması}},
year = {2019}
}
@article{Munasinghe,
author = {Munasinghe, Ranjiva},
file = {:home/jeff/Downloads/ptsuite{\_}vignette.pdf:pdf},
keywords = {Power law distributions, fat tailed distributions,,fat tailed distributions,heavy tailed distributions,pareto distributions,power law distributions,r,tail estimation,tail index},
title = {{Tail Index Estimation for Power Law Distributions in R}}
}
@article{Murdoch2006,
abstract = {It is commonly believed that steganography within TCP/IP is easily achieved by embedding data in header fields seemingly filled with "random" data, such as the IP identifier, TCP initial sequence number (ISN) or the least significant bit of the TCP timestamp. We show that this is not the case; these fields naturally exhibit sufficient structure and non-uniformity to be efficiently and reliably differentiated from unmodified ciphertext. Previous work on TCP/IP steganography does not take this into account and, by examining TCP/IP specifications and open source implementations, we have developed tests to detect the use of na{\"{i}}ve embedding. Finally, we describe reversible transforms that map block cipher output onto TCP ISNs, indistinguishable from those generated by Linux and OpenBSD. The techniques used can be extended to other operating systems. A message can thus be hidden so that an attacker cannot demonstrate its existence without knowing a secret key. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
author = {Murdoch, Steven J. and Lewis, Stephen},
doi = {10.1007/11558859_19},
isbn = {3540290397},
issn = {16113349},
journal = {Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)},
pages = {247--261},
publisher = {Springer Verlag},
title = {{Embedding covert channels into TCP/IP}},
volume = {3727 LNCS},
year = {2006}
}
@article{Homayoun2016,
author = {Homayoun, Sajad and Ahmadzadeh, Marzieh},
doi = {10.14419/jacst.v5i1.5225},
file = {:home/jeff/Downloads/A{\_}review{\_}on{\_}data{\_}stream{\_}classification{\_}approaches.pdf:pdf},
keywords = {active learning,data stream,data stream classification,ensemble,semi-supervised learning},
number = {May},
title = {{A review on data stream classification approaches}},
year = {2016}
}
@article{Nadarajah2018,
abstract = {We derive single integral representations for the exact distribution of the sum of independent generalized Pareto random variables. The integrands involve the incomplete and complementary incomplete gamma functions. Applications to insurance and catastrophe bonds are described.},
author = {Nadarajah, Saralees and Zhang, Yuanyuan and Pog{\'{a}}ny, Tibor K.},
doi = {10.1017/S0269964817000055},
file = {:home/jeff/Downloads/Prob{\_}Eng{\_}Inf{\_}Sci{\_}322{\_}2018{\_}Pareto.pdf:pdf},
issn = {14698951},
journal = {Probab. Eng. Informational Sci.},
keywords = {Characteristic function,Generalized pareto distribution,Incomplete gamma function},
number = {2},
pages = {296--305},
title = {{On sums of independent generalized pareto random variables with applications to insurance and cat bonds}},
volume = {32},
year = {2018}
}
@article{Knight2011,
author = {Knight, Simon and Nguyen, Hung X and Falkner, Nickolas and Bowden, Rhys and Roughan, Matthew},
file = {:home/jeff/Downloads/topology{\_}zoo.pdf:pdf},
pages = {1--12},
title = {{The Internet Topology Zoo}},
year = {2011}
}
@article{Loning2019,
abstract = {We present sktime -- a new scikit-learn compatible Python library with a unified interface for machine learning with time series. Time series data gives rise to various distinct but closely related learning tasks, such as forecasting and time series classification, many of which can be solved by reducing them to related simpler tasks. We discuss the main rationale for creating a unified interface, including reduction, as well as the design of sktime's core API, supported by a clear overview of common time series tasks and reduction approaches.},
archivePrefix = {arXiv},
arxivId = {1909.07872},
author = {L{\"{o}}ning, Markus and Bagnall, Anthony and Ganesh, Sajaysurya and Kazakov, Viktor and Lines, Jason and Kir{\'{a}}ly, Franz J.},
eprint = {1909.07872},
month = {sep},
title = {{sktime: A Unified Interface for Machine Learning with Time Series}},
url = {http://arxiv.org/abs/1909.07872},
year = {2019}
}
@article{Kumar2020,
abstract = {Time series analysis and prediction have been widely accepted in various domains from last two decades. Business analytics, Medical drugs {\&} pharmaceutical, Dynamic Marketing, Weather forecasting, Pollution measures, financial portfolio analysis and Stock market prediction are the favorite domains among research communities under time series analysis. Since air Time series analysis and prediction have been widely accepted in various domains from last two decades. Business analytics, quality is one of the paramount factors which make life possible on earth and monitoring air quality data as time series Medical drugs {\&} pharmaceutical, Dynamic Marketing, Weather forecasting, Pollution measures, financial portfolio analysis analysis is a one of prime area. The most affected air quality parameters on health are carbon monoxide (CO),carbon dioxide and Stock market prediction are the favorite domains among research communities under time series analysis. Since air quality is one of the paramount factors which make life possible on earth and monitoring air quality data as time series (CO2), Ammonia(NH3) and Acetone ((CH3)2CO). In this paper we have taken the sensor's data of three specific locations of Delhi and National Capital Region (NCR) and predict air quality of next day using linear regression as machine learning analysis is a one of prime area. The most affected air quality parameters on health are carbon monoxide (CO),carbon dioxide (CO2), Ammonia(NH3) and Acetone ((CH3)2CO). In this paper we have taken the sensor's data of three specific locations of algorithm. Model is evaluated through four performance measures Mean Absolute Error (MAE), Mean Square Error (MSE), Delhi and National Capital Region (NCR) and predict air quality of next day using linear regression as machine learning Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE). The study further assesses with benchmark algorithm. Model is evaluated through four performance measures Mean Absolute Error (MAE), Mean Square Error (MSE), model and obtains significant results. Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE). The study further assesses with benchmark model and obtains significant results. {\textcopyright}},
author = {Kumar, Raghavendra},
doi = {10.1016/j.procs.2020.03.240},
file = {:home/jeff/Downloads/1-s2.0-S1877050920307067-main.pdf:pdf},
issn = {1877-0509},
journal = {Procedia Comput. Sci.},
keywords = {ARIMA,Machine Learning,Regression Model,Time series},
number = {2019},
pages = {373--381},
publisher = {Elsevier B.V.},
title = {{ScienceDirect ScienceDirect ScienceDirect Time Series Data Prediction using IoT and Machine Learning Technique Time Series Data Prediction using IoT and Machine Learning Technique}},
url = {https://doi.org/10.1016/j.procs.2020.03.240},
volume = {167},
year = {2020}
}
@article{Pang2021,
abstract = {Traffic classification associates packet streams with known application labels, which is vital for network security and network management. With the rise of NAT, port dynamics, and encrypted traffic, it is increasingly challenging to obtain unified traffic features for accurate classification. Many state-of-the-art traffic classifiers automatically extract features from the packet stream based on deep learning models such as convolution networks. Unfortunately, the compositional and causal relationships between packets are not well extracted in these deep learning models, which affects both prediction accuracy and generalization on different traffic types. In this paper, we present a chained graph model on the packet stream to keep the chained compositional sequence. Next, we propose CGNN, a graph neural network based traffic classification method, which builds a graph classifier over automatically extracted features over the chained graph. Extensive evaluation over real-world traffic data sets, including normal, encrypted and malicious labels, show that, CGNN improves the prediction accuracy by 23$\backslash${\%} to 29$\backslash${\%} for application classification, by 2$\backslash${\%} to 37$\backslash${\%} for malicious traffic classification, and reaches the same accuracy level for encrypted traffic classification. CGNN is quite robust in terms of the recall and precision metrics. We have extensively evaluated the parameter sensitivity of CGNN, which yields optimized parameters that are quite effective for traffic classification.},
archivePrefix = {arXiv},
arxivId = {2110.09726},
author = {Pang, Bo and Fu, Yongquan and Ren, Siyuan and Wang, Ye and Liao, Qing and Jia, Yan},
eprint = {2110.09726},
file = {:home/jeff/Downloads/2110.09726v1.pdf:pdf},
journal = {Proc. ACM Conf.},
keywords = {Appl,Graph neural network,Traffic classification,application classifica-,graph neural network,traffic classification},
month = {oct},
number = {1},
publisher = {Association for Computing Machinery},
title = {{CGNN: Traffic Classification with Graph Neural Network}},
url = {http://arxiv.org/abs/2110.09726},
volume = {1},
year = {2021}
}
@inproceedings{Popescu2008,
author = {Constantinescu, Doru and Popescu, Adrian},
booktitle = {Adv. Int'l Conf. Telecommun. Int'l Conf. Internet Web Appl. Serv.},
doi = {10.1109/AICT-ICIW.2006.132},
file = {:home/jeff/Downloads/FULLTEXT01.pdf:pdf},
isbn = {0-7695-2522-9},
keywords = {capturing software,ip routers,one-way transit time,traffic,traffic measurements,traffic modeling,traffic self-similarity},
pages = {16--16},
publisher = {IEEE},
title = {{Modeling of One-Way Transit Time in IP Routers}},
url = {http://ieeexplore.ieee.org/document/1602148/},
year = {2006}
}
@article{Mehdiyev2017,
author = {Mehdiyev, Nijat and Lahann, Johannes and Emrich, Andreas and Enke, David and Fettke, Peter and Loos, Peter},
doi = {10.1016/j.procs.2017.09.066},
file = {:home/jeff/Downloads/1-s2.0-S1877050917318707-main.pdf:pdf},
issn = {1877-0509},
journal = {Procedia Comput. Sci.},
keywords = {Deep Learning,Process Industry,Steel Surface Defect Detection,Time Series Classification,deep learning,process industry,steel surface defect detection,time series classification},
pages = {242--249},
publisher = {Elsevier B.V.},
title = {{Time Series Classification using Deep Learning for Process Planning : A Case from the Process Industry}},
url = {https://doi.org/10.1016/j.procs.2017.09.066},
volume = {114},
year = {2017}
}
@article{Parker2020,
abstract = {Time series classification using novel techniques has experienced a recent resurgence and growing interest from statisticians, subject-domain scientists, and decision makers in business and industry. This is primarily due to the ever increasing amount of big and complex data produced as a result of technological advances. A motivating example is that of Google trends data, which exhibit highly nonlinear behavior. Although a rich literature exists for addressing this problem, existing approaches mostly rely on first- and second-order properties of the time series, since they typically assume linearity of the underlying process. Often, these are inadequate for effective classification of nonlinear time series data such as Google Trends data. Given these methodological deficiencies and the abundance of nonlinear time series that persist among real-world phenomena, we introduce an approach that merges higher order spectral analysis with deep convolutional neural networks for classifying time series. The effectiveness of our approach is illustrated using simulated data and two motivating industry examples that involve Google trends data and electronic device energy consumption data.},
archivePrefix = {arXiv},
arxivId = {2003.02353},
author = {Parker, Paul A. and Holan, Scott H. and Ravishanker, Nalini},
doi = {10.1002/asmb.2536},
eprint = {2003.02353},
file = {:home/jeff/Downloads/2003.02353.pdf:pdf;:home/jeff/Downloads/WAIM2014.pdf:pdf},
issn = {15264025},
journal = {Appl. Stoch. Model. Bus. Ind.},
keywords = {deep learning,higher-order spectra,neural network algorithms,nonlinear time series,supervised learning},
number = {5},
pages = {877--890},
title = {{Nonlinear time series classification using bispectrum-based deep convolutional neural networks}},
volume = {36},
year = {2020}
}
@article{Krollner2010,
abstract = {Stock index forecasting is vital for making informed investment decisions. This paper surveys recent literature in the domain of machine learning techniques and artificial intelligence used to forecast stock market movements. The publications are categorised according to the machine learning technique used, the forecasting timeframe, the input variables used, and the evaluation techniques employed. It is found that there is a consensus between researchers stressing the importance of stock index forecasting. Artificial Neural Networks (ANNs) are identified to be the dominant machine learning technique in this area. We conclude with possible future research directions.},
author = {Krollner, Bjoern and Vanstone, Bruce and Finnie, Gavin},
file = {:home/jeff/Desktop/SynologyDrive/projekte/Bachelor/papers/Financial{\_}time{\_}series{\_}forecasting{\_}with{\_}machine{\_}learning{\_}techniques.pdf:pdf},
isbn = {2930307102},
journal = {Proc. 18th Eur. Symp. Artif. Neural Networks - Comput. Intell. Mach. Learn. ESANN 2010},
pages = {25--30},
title = {{Financial time series forecasting with machine learning techniques: A survey}},
year = {2010}
}
@article{Berk2005,
author = {Berk, Vincent and Giani, A. and Cybenko, C.},
title = {{Detection of Covert Channel Encoding in Network Packet Delays}},
year = {2005}
}
@article{perera2017,
author = {Perera, Pramitha and Tian*, Yu-Chu and Fidge, Colin and Kelly, Wayne},
doi = {10.1007/978-3-319-70093-9},
file = {:home/jeff/Downloads/typeinst{\_}v6{\_}Pramitha{\_}withPubInformation.pdf:pdf},
isbn = {9783319700878},
title = {{A Comparison of Supervised Machine Learning Algorithms for Classification of Communications Network Traffic}},
year = {2017}
}
@article{Alemdar2020,
author = {Alemdar, Hande and Onur, Ertan},
file = {:home/jeff/Desktop/SynologyDrive/projekte/Bachelor/papers/timing covert channels/Covert{\_}Channel{\_}Detection{\_}Using{\_}Machine{\_}Learning.pdf:pdf},
isbn = {9781728172064},
keywords = {covert channel,covert channel detection,daha sonra,decision tree,her bir sembol{\"{u}} yollarken,hine learning,kar,mac-,mesajı g{\"{o}}nderen taraf,zaman farkı tanımlanır},
pages = {2020--2023},
title = {{Makine {\"{O}} ˘ grenmesi ile {\"{O}}rt{\"{u}}l{\"{u}} Kanalların Tespiti Covert Channel Detection Using Machine Learning}},
year = {2020}
}
@phdthesis{Fremond2021,
author = {Fremond, Alexis},
file = {:home/jeff/Downloads/2020UPSLD017(2).pdf:pdf},
title = {{Statistical modeling and analysis of Internet latency traffic data}},
year = {2021}
}
@article{Martinez2022,
abstract = {Time series forecasting plays a key role in many fields such as business, energy or environment. Traditionally, statistical or machine learning models for time series forecasting are trained with the historical values of the series to be forecast. Unfortunately, some time series are too short to suitably train a model. Motivated by this fact, this paper explores the use of data available in a pool or collection of time series to train a model that predicts an individual series. Concretely, we train a generalized regression neural network with the examples drawn from the historical values of a pool of series and then use the model to forecast individual series. In this sense several approaches are proposed, including to draw the examples from a pool of series related to the series to be forecast or the training of several models with mutually exclusive series and the combination of their forecasts. Experimental results in terms of forecasting accuracy using generalized regression neural networks are promising. Furthermore, the proposed approaches allow to forecast series that are too short to build a traditional generalized regression neural network model.},
author = {Martinez, Francisco and Frias, Maria P. and Perez-Godoy, Maria D. and Rivera, Antonio J.},
doi = {10.1109/ACCESS.2022.3140377},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martinez et al. - 2022 - Time Series Forecasting by Generalized Regression Neural Networks Trained With Multiple Series.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Generalized regression neural networks,Model combination,Time series forecasting},
pages = {3275--3283},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Time Series Forecasting by Generalized Regression Neural Networks Trained With Multiple Series}},
volume = {10},
year = {2022}
}
@misc{scapy,
title = {{GitHub - secdev/scapy: Scapy: the Python-based interactive packet manipulation program {\&} library}},
url = {https://github.com/secdev/scapy{\#}sponsor-button-repo},
urldate = {2022-05-23}
}
@article{Qi2010,
author = {Qi, Yongcheng},
doi = {10.1007/s10463-008-0176-2},
file = {:home/jeff/Downloads/10aism.pdf:pdf},
isbn = {1046300801762},
keywords = {confidence interval,coverage probability,edgeworth expansion,empirical likelihood,tail index estimation},
number = {April 2008},
pages = {277--298},
title = {{On the tail index of a heavy tailed distribution}},
year = {2010}
}
@article{Bovy,
author = {Bovy, C. J. and Mertodimedjo, H. T. and Hooghiemstra, G. and Uijterwaal, H. and Mieghem, P. Van},
file = {:home/jeff/Downloads/PAM2002.pdf:pdf},
title = {{Analysis of End-to-end Delay Measurements in Internet}},
year = {2002}
}
@article{Hillmann2015,
abstract = {IP Geolocation is a key enabler for many areas of application like Content Delivery Networks, targeted advertisement and law enforcement. Therefore, an increased accuracy is needed to improve service quality. Although IP Geolocation is an ongoing field of research for over one decade, it is still a challenging task, whereas good results are only achieved by the use of active latency measurements. This paper presents an novel approach to find optimized Landmarks positions which are used for active probing and introduce an improved location estimation. Since a reasonable Landmark selection is important for a highly accurate localization service, the goal is to find Landmarks close to the target with respect to the infrastructure and hop count. Current techniques provide less information about solving this problem as well as are using imprecise models. We demonstrate the usability of our approach in a real-world environment. The combination of an optimized Landmark selection and advanced modulation results in an improved accuracy of IP Geolocation.},
archivePrefix = {arXiv},
arxivId = {2004.07836},
author = {Hillmann, Peter and Stiemert, Lars and Rodosek, Gabi Dreo and Rose, Oliver},
eprint = {2004.07836},
file = {:home/jeff/Downloads/2004.07836.pdf:pdf},
isbn = {9783901882777},
month = {apr},
pages = {173--177},
title = {{Modelling of IP Geolocation by use of Latency Measurements}},
url = {http://arxiv.org/abs/2004.07836},
year = {2020}
}
@article{Ruiz2020,
abstract = {Time Series Classification (TSC) involved building predictive models for a discrete target variable from ordered, real valued, attributes. Over recent years, a new set of TSC algorithms have been developed which have made significant improvement over the previous state of the art. The main focus has been on univariate TSC, i.e. the problem where each case has a single series and a class label. In reality, it is more common to encounter multivariate TSC (MTSC) problems where multiple series are associated with a single label. Despite this, much less consideration has been given to MTSC than the univariate case. The UEA archive of 30 MTSC problems released in 2018 has made comparison of algorithms easier. We review recently proposed bespoke MTSC algorithms based on deep learning, shapelets and bag of words approaches. The simplest approach to MTSC is to ensemble univariate classifiers over the multivariate dimensions. We compare the bespoke algorithms to these dimension independent approaches on the 26 of the 30 MTSC archive problems where the data are all of equal length. We demonstrate that the independent ensemble of HIVE-COTE classifiers is the most accurate, but that, unlike with univariate classification, dynamic time warping is still competitive at MTSC.},
archivePrefix = {arXiv},
arxivId = {2007.13156},
author = {Ruiz, Alejandro Pasos and Flynn, Michael and Bagnall, Anthony},
doi = {10.1007/s10618-020-00727-3},
eprint = {2007.13156},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruiz, Flynn, Bagnall - 2020 - Benchmarking Multivariate Time Series Classification Algorithms.pdf:pdf},
journal = {Data Min. Knowl. Discov. 2020 352},
keywords = {Artificial Intelligence,Chemistry and Earth Sciences,Computer Science,Data Mining and Knowledge Discovery,Information Storage and Retrieval,Physics,Statistics for Engineering},
month = {jul},
number = {2},
pages = {401--449},
publisher = {Springer},
title = {{Benchmarking Multivariate Time Series Classification Algorithms}},
url = {http://arxiv.org/abs/2007.13156 http://dx.doi.org/10.1007/s10618-020-00727-3},
volume = {35},
year = {2020}
}
@book{Chen2020,
author = {Chen, Xiaofeng and Eds, Xiangliang Zhang and Goos, Gerhard},
file = {:home/jeff/Downloads/Papers/2020{\_}Book{\_}MachineLearningForCyberSecurit.pdf:pdf},
isbn = {9783030622220},
title = {{Machine Learning for Cyber Security}},
year = {2020}
}
@article{Wendzel2015,
abstract = {Network covert channels are used to hide communication inside network protocols. Various techniques for covert channels have arisen in the past few decades. We surveyed and analyzed 109 techniques developed between 1987 and 2013 and show that these techniques can be reduced to only 11 different patterns. Moreover, the majority (69.7{\%}) of techniques can be categorized into only four different patterns (i.e., most techniques we surveyed are similar). We represent the patterns in a hierarchical catalog using a pattern language. Our pattern catalog will serve as a base for future covert channel novelty evaluation. Furthermore, we apply the concept of pattern variations to network covert channels. With pattern variations, the context of a pattern can change. For example, a channel developed for IPv4 can automatically be adapted to other network protocols. We also propose the pattern-based covert channel optimizations pattern hopping and pattern combination. Finally, we lay the foundation for pattern-based countermeasures: whereas many current countermeasures were developed for specific channels, a pattern-oriented approach allows application of one countermeasure to multiple channels. Hence, future countermeasure development can focus on patterns, and the development of real-world protection against covert channels is greatly simplified.},
author = {Wendzel, Steffen and Zander, Sebastian and Fechner, Bernhard and Herdin, Christian},
doi = {10.1145/2684195},
file = {:home/jeff/Downloads/document.pdf:pdf},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
month = {apr},
number = {3},
pages = {1--26},
title = {{Pattern-Based Survey and Categorization of Network Covert Channel Techniques}},
url = {https://dl.acm.org/doi/10.1145/2684195},
volume = {47},
year = {2015}
}
@article{Cabuk2009,
abstract = {A covert channel can occur when an attacker finds and exploits a shared resource that is not designed to be a communication mechanism. A network covert channel operates by altering the timing of otherwise legitimate network traffic so that the arrival times of packets encode confidential data that an attacker wants to exfiltrate from a secure area from which she has no other means of communication. In this article, we present the first public implementation of an IP covert channel, discuss the subtle issues that arose in its design, and present a discussion on its efficacy. We then show that an IP covert channel can be differentiated from legitimate channels and present new detection measures that provide detection rates over 95{\%}. We next take the simple step an attacker would of adding noise to the channel to attempt to conceal the covert communication. For these noisy IP covert timing channels, we show that our online detection measures can fail to identify the covert channel for noise levels higher than 10{\%}. We then provide effective offline search mechanisms that identify the noisy channels.},
author = {Cabuk, Serdar and Brodley, Carla E. and Shields, Clay},
doi = {10.1145/1513601.1513604},
issn = {1094-9224},
journal = {ACM Trans. Inf. Syst. Secur.},
keywords = {Channel detection,Information hiding,Network covert channels},
month = {apr},
number = {4},
pages = {1--29},
title = {{IP Covert Channel Detection}},
url = {https://dl.acm.org/doi/10.1145/1513601.1513604},
volume = {12},
year = {2009}
}
@article{Schmidbauer,
author = {Schmidbauer, Tobias and Wendzel, Steffen},
doi = {10.22667/JOWUA.2022.03.31.137},
file = {:home/jeff/Downloads/02{\_}5{\_}Threshold{\_}Detection{\_}JoWUA{\_}2022.pdf:pdf},
title = {{Detection Of Computational Intensive Reversible Covert Channels Based On Packet Runtime}},
year = {2022}
}
@article{Akiyama2022,
author = {Akiyama, Takanori and Tanaka, Gouhei},
doi = {10.1109/ACCESS.2022.3158755},
file = {:home/jeff/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Akiyama, Tanaka - 2022 - Computational Efficiency of Multi-Step Learning Echo State Networks for Nonlinear Time Series Prediction.pdf:pdf},
issn = {2169-3536},
journal = {IEEE Access},
pages = {28535--28544},
title = {{Computational Efficiency of Multi-Step Learning Echo State Networks for Nonlinear Time Series Prediction}},
url = {https://ieeexplore.ieee.org/document/9732994/},
volume = {10},
year = {2022}
}
@article{Kolouri2016,
abstract = {Optimal transport distances, otherwise known as Wasserstein distances, have recently drawn ample attention in computer vision and machine learning as powerful discrepancy measures for probability distributions. The recent developments on alternative formulations of the optimal transport have allowed for faster solutions to the problem and have revamped their practical applications in machine learning. In this paper, we exploit the widely used kernel methods and provide a family of provably positive definite kernels based on the Sliced Wasserstein distance and demonstrate the benefits of these kernels in a variety of learning tasks. Our work provides a new perspective on the application of optimal transport flavored distances through kernel methods in machine learning tasks.},
archivePrefix = {arXiv},
arxivId = {1511.03198},
author = {Kolouri, Soheil and Zou, Yang and Rohde, Gustavo K.},
doi = {10.1109/CVPR.2016.568},
eprint = {1511.03198},
file = {:home/jeff/Downloads/Kolouri{\_}Sliced{\_}Wasserstein{\_}Kernels{\_}CVPR{\_}2016{\_}paper.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.},
pages = {5258--5267},
title = {{Sliced Wasserstein kernels for probability distributions}},
volume = {2016-Decem},
year = {2016}
}
